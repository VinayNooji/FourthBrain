{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4B_AutoML_Deployment_on_GCP_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinayNooji/FourthBrain/blob/main/4B_AutoML_Deployment_on_GCP_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4H8UJlKRl6P"
      },
      "source": [
        "# This code book is modified version of original\n",
        "https://cloud.google.com/ai-platform/docs/getting-started-keras\n",
        " # to cater to the classroom instruction format at FourthBrain\n",
        "\n",
        " # This provides a solution to transfer data from your Google Drive and run on AI Platform in GCP through GCP. \n",
        " # Please run this code on Colab for complete learning experience.\n",
        "\n",
        " 1. Ensure your gmail that you connect with Colab has been added to a GCP project\n",
        " 2. Authenticate Colab to access your Google drive. This surpasses the need for Google authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "deletable": true,
        "editable": true,
        "id": "qnMpW5Y9nv2l"
      },
      "source": [
        "# Copyright 2019 Google LLC\n",
        "# Redo for region= US-east1\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mHF9VCProKJN"
      },
      "source": [
        "# Getting started: Training and prediction with Keras in AI Platform\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/ai-platform/census/keras-tensorflow-cmle.png\" alt=\"Keras, TensorFlow, and AI Platform logos\" width=\"300px\">\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-keras\">\n",
        "      <img src=\"https://cloud.google.com/_static/images/cloud/icons/favicons/onecloud/super_cloud.png\"\n",
        "           alt=\"Google Cloud logo\" width=\"32px\"> Read on cloud.google.com\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/cloudml-samples/blob/master/notebooks/tensorflow/getting-started-keras.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/notebooks/tensorflow/getting-started-keras.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hZzRVxNtH-zG"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial shows how to train a neural network on AI Platform\n",
        "using the Keras sequential API and how to serve predictions from that\n",
        "model.\n",
        "\n",
        "Keras is a high-level API for building and training deep learning models.\n",
        "[tf.keras](https://www.tensorflow.org/guide/keras) is TensorFlowâ€™s\n",
        "implementation of this API.\n",
        "\n",
        "The first two parts of the tutorial walk through training a model on Cloud\n",
        "AI Platform using prewritten Keras code, deploying the trained model to\n",
        "AI Platform, and serving online predictions from the deployed model.\n",
        "\n",
        "The last part of the tutorial digs into the training code used for this model and ensuring it's compatible with AI Platform. To learn more about building\n",
        "machine learning models in Keras more generally, read [TensorFlow's Keras\n",
        "tutorials](https://www.tensorflow.org/tutorials/keras)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iN69d4D9Flrh"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses the [United States Census Income\n",
        "Dataset](https://archive.ics.uci.edu/ml/datasets/census+income) provided by the\n",
        "[UC Irvine Machine Learning\n",
        "Repository](https://archive.ics.uci.edu/ml/index.php). This dataset contains\n",
        "information about people from a 1994 Census database, including age, education,\n",
        "marital status, occupation, and whether they make more than $50,000 a year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Su2qu-4CW-YH"
      },
      "source": [
        "### Objective\n",
        "\n",
        "The goal is to train a deep neural network (DNN) using Keras that predicts\n",
        "whether a person makes more than $50,000 a year (target label) based on other\n",
        "Census information about the person (features).\n",
        "\n",
        "This tutorial focuses more on using this model with AI Platform than on\n",
        "the design of the model itself. However, it's always important to think about\n",
        "potential problems and unintended consequences when building machine learning\n",
        "systems. See the [Machine Learning Crash Course exercise about\n",
        "fairness](https://developers.google.com/machine-learning/crash-course/fairness/programming-exercise)\n",
        "to learn about sources of bias in the Census dataset, as well as machine\n",
        "learning fairness more generally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "i2qsxysTVc-l"
      },
      "source": [
        "# Start here\n",
        "### Setting up your GCP project\n",
        "\n",
        "**The following steps are required to start a new project. You currently have access to the FourthBrain Project, so step 1 and 2 are NOT applicable for now.**\n",
        "\n",
        "1. [Select or create a GCP project.](https://console.cloud.google.com/cloud-resource-manager)\n",
        "\n",
        "2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project). \n",
        "\n",
        "**For the Live assignment start from here.**\n",
        "\n",
        "3. [Enable the AI Platform (\"Cloud Machine Learning Engine\") and Compute Engine APIs.](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component)\n",
        "\n",
        "4. Enter your project ID in the cell below. Then run the  cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook. \n",
        "# **Dont change the settings below for Live assignment.**\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4qxwBA4RM9Lu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d4d41f-e0a6-4b90-e226-685d3ea89af8"
      },
      "source": [
        "PROJECT_ID = \"fb-mle-march-21\" #@param {type:\"string\"}\n",
        "! gcloud config set project $PROJECT_ID"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TSy-f05IO4LB"
      },
      "source": [
        "### Authenticate your GCP account\n",
        "\n",
        "**If you are using AI Platform Notebooks**, your environment is already\n",
        "authenticated. Skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fZQUrHdXNJnk"
      },
      "source": [
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIr048-DPUge",
        "outputId": "f51c21a9-5770-439a-f278-85beb7740711"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Znf1aqUDRBP",
        "outputId": "d75dd7f7-44f5-4060-edb9-3408db11c5ff"
      },
      "source": [
        "# The path below should point to the directory containing this notebook and the associated utility files\n",
        "# Change it if necessary\n",
        "os.chdir('/content/drive/MyDrive/FourthBrain/Week13/Live')\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4B_AutoML_Deployment_on_GCP_v1.ipynb  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tT061irlJwkg"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-console\n",
        "When you submit a training job using the Cloud SDK, you upload a Python package\n",
        "containing your training code to a Cloud Storage bucket. AI Platform runs\n",
        "the code from this package. In this tutorial, AI Platform also saves the\n",
        "trained model that results from your job in the same bucket. You can then\n",
        "create an AI Platform model version based on this output in order to serve\n",
        "online predictions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
        "Cloud Storage buckets. \n",
        "\n",
        "# Do Not change the settings below for Live Assignment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bTxmbDg1I0x1"
      },
      "source": [
        "BUCKET_NAME = \"nooji-test-bucket\" #@param {type:\"string\"}\n",
        "REGION = \"us-east1\" #@param {type:\"string\"}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fsmCk2dwJnLZ"
      },
      "source": [
        "# Task 1: Create your Cloud Storage bucket. https://cloud.google.com/storage/docs/creating-buckets\n",
        "\n",
        "## Give any name to your bitbucket. **Select Region as US-east 1.**\n",
        "Hit create. Once you run the command below, you should be able to see the bitbucket associated.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxGTn3hqkdOy",
        "outputId": "fff0e82d-22d6-4dba-ab3f-25412a1551a3"
      },
      "source": [
        "#This will check connection and list the connected data bucket. Ensure Bitbucket created before this.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "project_id = PROJECT_ID\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://abgrtyu/\n",
            "gs://abhi1/\n",
            "gs://anthonyho/\n",
            "gs://artifacts.fb-mle-march-21.appspot.com/\n",
            "gs://automl-experiment-fourthbrain-alessiot/\n",
            "gs://automl-experiment-fourthbrain-daniel/\n",
            "gs://automl-experiment-fourthbrain-jt/\n",
            "gs://automl-experiment-fourthbrain-mm/\n",
            "gs://automl-experiment-fourthbrain-russell/\n",
            "gs://bernie/\n",
            "gs://ethan-lewis-4b-bucket/\n",
            "gs://fb-karsten-test/\n",
            "gs://fb-mle-march-21-jida/\n",
            "gs://fb-mle-march-21-tf2-models/\n",
            "gs://fb-mle-march-21.appspot.com/\n",
            "gs://jgiri-automl-experiment-fourthbrain/\n",
            "gs://kei_4b_bucket/\n",
            "gs://manny_glg/\n",
            "gs://mbaugh_4b_bucket0/\n",
            "gs://mikhail2/\n",
            "gs://misbah1/\n",
            "gs://moha_bucket_1/\n",
            "gs://nooji-test-bucket/\n",
            "gs://paulo-test-fb/\n",
            "gs://rsinghal/\n",
            "gs://samsung-oct/\n",
            "gs://shayansombol/\n",
            "gs://spatikaganesh/\n",
            "gs://staging.fb-mle-march-21.appspot.com/\n",
            "gs://us.artifacts.fb-mle-march-21.appspot.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aRVMEU2Qshm4"
      },
      "source": [
        "## Part 1. Quickstart for training in AI Platform\n",
        "\n",
        "This section of the tutorial walks you through submitting a training job to Cloud\n",
        "AI Platform. This job runs sample code that uses Keras to train a deep neural\n",
        "network on the United States Census data. It outputs the trained model as a\n",
        "[TensorFlow SavedModel\n",
        "directory](https://www.tensorflow.org/guide/saved_model#save_and_restore_models)\n",
        "in your Cloud Storage bucket.\n",
        "\n",
        "**Details of pre-trained weights: cloudml-samples->tf-keras->trainer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8zr6lj66UlMn"
      },
      "source": [
        "### Get training code and dependencies\n",
        "\n",
        "First, download the training code and change the notebook's working directory. The code and data get downloaded to your GDrive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Icz22E69smnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000ae7ed-40d6-4e2f-995d-f971460653e6"
      },
      "source": [
        "# Clone the repository of AI Platform samples\n",
        "! git clone --depth 1 https://github.com/GoogleCloudPlatform/cloudml-samples\n",
        "\n",
        "# Set the working directory to the sample code directory\n",
        "%cd cloudml-samples/census/tf-keras"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloudml-samples'...\n",
            "remote: Enumerating objects: 596, done.\u001b[K\n",
            "remote: Counting objects: 100% (596/596), done.\u001b[K\n",
            "remote: Compressing objects: 100% (461/461), done.\u001b[K\n",
            "remote: Total 596 (delta 163), reused 327 (delta 87), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (596/596), 23.26 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n",
            "Checking out files: 100% (528/528), done.\n",
            "/content/drive/My Drive/FourthBrain/Week13/Live/cloudml-samples/census/tf-keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MhubJDDXSVv3"
      },
      "source": [
        "Notice that the training code is structured as a Python package in the\n",
        "`trainer/` subdirectory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uZ_nfuPJlNpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a0814f-258c-4e94-dbf6-62cd7f796e32"
      },
      "source": [
        "# `ls` shows the working directory's contents. The `p` flag adds trailing \n",
        "# slashes to subdirectory names. The `R` flag lists subdirectories recursively.\n",
        "! ls -pR"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".:\n",
            "hptuning_config.yaml  README.md  requirements.txt  scripts/  trainer/\n",
            "\n",
            "./scripts:\n",
            "train-local.sh\n",
            "\n",
            "./trainer:\n",
            "__init__.py  model.py  task.py\tutil.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7KA87o4HUhby"
      },
      "source": [
        "Run the following cell to install Python dependencies needed to train the model locally. When you run the training job in AI Platform,\n",
        "dependencies are preinstalled based on the [runtime\n",
        "version](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
        "you choose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Wm5w1UrmVU7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159ca674-3931-43cd-b731-af350d28f501"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: six>=1.11 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.15.0)\n",
            "Collecting tensorflow<2,>=1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/99abd43185d94adaaaddf8f44a80c418a91977924a7bc39b8dacd0c495b0/tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110.5MB 79kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22->-r requirements.txt (line 2)) (2018.9)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (0.8.1)\n",
            "Collecting h5py<=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (1.34.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 4)) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 4)) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=7843840843cbdb942b187e47639daff58add1ab3dcc6fce7d764db554c245e21\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 1.15.5 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, h5py, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iSrzwuchvcgv"
      },
      "source": [
        "### Train your model locally\n",
        "\n",
        "Before training on AI Platform, train the job locally to verify the file\n",
        "structure and packaging is correct.\n",
        "\n",
        "For a complex or resource-intensive job, you\n",
        "may want to train locally on a small sample of your dataset to verify your code.\n",
        "Then you can run the job on AI Platform to train on the whole dataset.\n",
        "\n",
        "This sample runs a relatively quick job on a small dataset, so the local\n",
        "training and the AI Platform job run the same code on the same data.\n",
        "\n",
        "Run the following cell to train a model locally:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "D5PIljnYveDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795ec88e-8d39-4cb8-f780-d9fc71f3173e"
      },
      "source": [
        "# Explicitly tell `gcloud ai-platform local train` to use Python 3 \n",
        "! gcloud config set ml_engine/local_python $(which python3)\n",
        "\n",
        "# This is similar to `python -m trainer.task --job-dir local-training-output`\n",
        "# but it better replicates the AI Platform environment, especially for\n",
        "# distributed training (not applicable here).\n",
        "! gcloud ai-platform local train \\\n",
        "  --package-path trainer \\\n",
        "  --module-name trainer.task \\\n",
        "  --job-dir local-training-output"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [ml_engine/local_python].\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2021-06-19 17:38:07.729110: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-06-19 17:38:07.732869: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2021-06-19 17:38:07.733143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5558a4176840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-19 17:38:07.733191: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Train on 254 steps, validate on 1 steps\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
            "Epoch 1/20\n",
            "2021-06-19 17:38:08.412851: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.\n",
            "254/254 [==============================] - 1s 3ms/step - loss: 0.4781 - acc: 0.7876 - val_loss: 0.3579 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
            "Epoch 2/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3527 - acc: 0.8380 - val_loss: 0.3535 - val_acc: 0.8395\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
            "Epoch 3/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3398 - acc: 0.8445 - val_loss: 0.3409 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
            "Epoch 4/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3356 - acc: 0.8452 - val_loss: 0.3291 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
            "Epoch 5/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3315 - acc: 0.8464 - val_loss: 0.3340 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
            "Epoch 6/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3314 - acc: 0.8469 - val_loss: 0.3269 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
            "Epoch 7/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3298 - acc: 0.8462 - val_loss: 0.3324 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
            "Epoch 8/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3277 - acc: 0.8491 - val_loss: 0.3253 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
            "Epoch 9/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3291 - acc: 0.8490 - val_loss: 0.3317 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
            "Epoch 10/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3255 - acc: 0.8487 - val_loss: 0.3238 - val_acc: 0.8492\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
            "Epoch 11/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3251 - acc: 0.8489 - val_loss: 0.3219 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.010004882812500001.\n",
            "Epoch 12/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8501 - val_loss: 0.3238 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.\n",
            "Epoch 13/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3277 - acc: 0.8500 - val_loss: 0.3303 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.\n",
            "Epoch 14/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3247 - acc: 0.8490 - val_loss: 0.3251 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.\n",
            "Epoch 15/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3235 - acc: 0.8509 - val_loss: 0.3422 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.01000030517578125.\n",
            "Epoch 16/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3237 - acc: 0.8493 - val_loss: 0.3289 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.010000152587890625.\n",
            "Epoch 17/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3233 - acc: 0.8512 - val_loss: 0.3275 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.010000076293945313.\n",
            "Epoch 18/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8509 - val_loss: 0.3378 - val_acc: 0.8534\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.010000038146972657.\n",
            "Epoch 19/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3221 - acc: 0.8519 - val_loss: 0.3204 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.010000019073486329.\n",
            "Epoch 20/20\n",
            "254/254 [==============================] - 1s 2ms/step - loss: 0.3234 - acc: 0.8513 - val_loss: 0.3332 - val_acc: 0.8490\n",
            "WARNING:tensorflow:From /content/drive/My Drive/FourthBrain/Week13/Live/cloudml-samples/census/tf-keras/trainer/task.py:123: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: local-training-output/keras_export/saved_model.pb\n",
            "Model exported to: local-training-output/keras_export\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rAX4hZip53SR"
      },
      "source": [
        "### Train your model using AI Platform\n",
        "\n",
        "Next, submit a training job to AI Platform. This runs the training module\n",
        "in the cloud and exports the trained model to Cloud Storage.\n",
        "\n",
        "First, give your training job a name and choose a directory within your Cloud\n",
        "Storage bucket for saving intermediate and output files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "05lDch9-0-2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3300b8c-d129-47e3-d11f-8591a25f2421"
      },
      "source": [
        "####ENTER HERE#############################################\n",
        "JOB_NAME = 'nooji_4B_keras_job' #Pick any name <Lastname_4B_keras_job>\n",
        "JOB_DIR = 'gs://' + BUCKET_NAME + '/keras-job-dir'\n",
        "print(JOB_DIR)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://nooji-test-bucket/keras-job-dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yp9nyrZ01a2q"
      },
      "source": [
        "Run the following command to package the `trainer/` directory, upload it to the\n",
        "specified `--job-dir`, and instruct AI Platform to run the\n",
        "`trainer.task` module from that package.\n",
        "\n",
        "The `--stream-logs` flag lets you view training logs in the cell below. You can\n",
        "also see logs and other job details in the GCP Console."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2WGqwAzc3xM"
      },
      "source": [
        "### Hyperparameter tuning\n",
        "## (This process will take the most time)!!!\n",
        "\n",
        "You can optionally perform hyperparameter tuning by using the included\n",
        "`hptuning_config.yaml` configuration file. This file tells AI Platform to tune the batch size and learning rate for training over multiple trials to maximize accuracy.\n",
        "\n",
        "In this example, the training code uses a [TensorBoard\n",
        "callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard),\n",
        "which [creates TensorFlow `Summary`\n",
        "`Event`s](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter#add_summary)\n",
        "during training. AI Platform uses these events to track the metric you want to\n",
        "optimize. Learn more about [hyperparameter tuning in\n",
        "AI Platform Training](https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview).\n",
        "\n",
        "# While you wait for this step to complete, you can check on GCP console that you job is running!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1haRe54v53CN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd74e3ec-313e-4fa5-9ceb-2e63c3fef218"
      },
      "source": [
        "! gcloud ai-platform jobs submit training $JOB_NAME \\\n",
        "  --package-path trainer/ \\\n",
        "  --module-name trainer.task \\\n",
        "  --region $REGION \\\n",
        "  --python-version 3.7 \\\n",
        "  --runtime-version 1.15 \\\n",
        "  --job-dir $JOB_DIR \\\n",
        "  --stream-logs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Job [nooji_4B_keras_job] submitted successfully.\n",
            "INFO\t2021-06-19 17:41:45 +0000\tservice\t\tValidating job requirements...\n",
            "INFO\t2021-06-19 17:41:45 +0000\tservice\t\tJob creation request has been successfully validated.\n",
            "INFO\t2021-06-19 17:41:45 +0000\tservice\t\tWaiting for job to be provisioned.\n",
            "INFO\t2021-06-19 17:41:46 +0000\tservice\t\tJob nooji_4B_keras_job is queued.\n",
            "INFO\t2021-06-19 17:41:48 +0000\tservice\t\tWaiting for training program to start.\n",
            "INFO\t2021-06-19 17:42:15 +0000\tmaster-replica-0\t\tUsing mount point: /gcs\n",
            "NOTICE\t2021-06-19 17:42:15 +0000\tmaster-replica-0\t\tOpening GCS connection...\n",
            "INFO\t2021-06-19 17:42:15 +0000\tmaster-replica-0\t\tSet up root directory for all accessible buckets\n",
            "NOTICE\t2021-06-19 17:42:15 +0000\tmaster-replica-0\t\tMounting file system \"gcsfuse\"...\n",
            "NOTICE\t2021-06-19 17:42:15 +0000\tmaster-replica-0\t\tFile system has been successfully mounted.\n",
            "INFO\t2021-06-19 17:42:17 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://nooji-test-bucket/keras-job-dir/packages/6b4226c9be10daf2e1b7eb7c238ba18ece4f289ff8e497988e7b4b1e9e226621/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"region\": \"us-east1\",  \"runtime_version\": \"1.15\",  \"job_dir\": \"gs://nooji-test-bucket/keras-job-dir\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.7\"}\n",
            "WARNING\t2021-06-19 17:42:25 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:698: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "WARNING\t2021-06-19 17:42:25 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:699: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
            "WARNING\t2021-06-19 17:42:25 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:700: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
            "WARNING\t2021-06-19 17:42:25 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:703: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "WARNING\t2021-06-19 17:42:25 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:704: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "INFO\t2021-06-19 17:42:29 +0000\tmaster-replica-0\t\tRunning module trainer.task.\n",
            "INFO\t2021-06-19 17:42:29 +0000\tmaster-replica-0\t\tDownloading the package: gs://nooji-test-bucket/keras-job-dir/packages/6b4226c9be10daf2e1b7eb7c238ba18ece4f289ff8e497988e7b4b1e9e226621/trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:29 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://nooji-test-bucket/keras-job-dir/packages/6b4226c9be10daf2e1b7eb7c238ba18ece4f289ff8e497988e7b4b1e9e226621/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:30 +0000\tmaster-replica-0\t\tInstalling the package: gs://nooji-test-bucket/keras-job-dir/packages/6b4226c9be10daf2e1b7eb7c238ba18ece4f289ff8e497988e7b4b1e9e226621/trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:30 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:31 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:31 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO\t2021-06-19 17:42:31 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "INFO\t2021-06-19 17:42:31 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n",
            "INFO\t2021-06-19 17:42:31 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\t  Created wheel for trainer: filename=trainer-0.0.0-py3-none-any.whl size=7893 sha256=41c7e79bae5414546c6541f0f501711f25a9c150e53d7bfc47ac2e9796696d50\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/23/ad/57/8e99a4eeb034edca80b0624cb205859d79e985819276530408\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n",
            "ERROR\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 20.1; however, version 21.1.2 is available.\n",
            "ERROR\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n",
            "INFO\t2021-06-19 17:42:32 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\t  Created wheel for trainer: filename=trainer-0.0.0-py3-none-any.whl size=7893 sha256=41c7e79bae5414546c6541f0f501711f25a9c150e53d7bfc47ac2e9796696d50\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/23/ad/57/8e99a4eeb034edca80b0624cb205859d79e985819276530408\n",
            "INFO\t2021-06-19 17:42:33 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\t  Attempting uninstall: trainer\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\t    Found existing installation: trainer 0.0.0\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\t    Uninstalling trainer-0.0.0:\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\t      Successfully uninstalled trainer-0.0.0\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n",
            "ERROR\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 20.1; however, version 21.1.2 is available.\n",
            "ERROR\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\tYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n",
            "INFO\t2021-06-19 17:42:34 +0000\tmaster-replica-0\t\tRunning command: python3 -m trainer.task --job-dir gs://nooji-test-bucket/keras-job-dir\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tCall initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tIf using Keras pass *_constraint arguments to layers.\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tOMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
            "INFO\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "INFO\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tCPU Frequency: 2299995000 Hz\n",
            "INFO\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\tXLA service 0x5621af0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "INFO\t2021-06-19 17:42:37 +0000\tmaster-replica-0\t\t  StreamExecutor device (0): Host, Default Version\n",
            "INFO\t2021-06-19 17:42:38 +0000\tmaster-replica-0\t\tProfiler session started.\n",
            "INFO\t2021-06-19 17:42:38 +0000\tmaster-replica-0\t\tTrain on 254 steps, validate on 1 steps\n",
            "INFO\t2021-06-19 17:42:38 +0000\tmaster-replica-0\t\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
            "INFO\t2021-06-19 17:42:38 +0000\tmaster-replica-0\t\tEpoch 1/20\n",
            "WARNING\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\tMethod (on_train_batch_end) is slow compared to the batch update (0.716349). Check your callbacks.\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 53s - loss: 0.6071 - acc: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t  2/254 [..............................] - ETA: 3:27 - loss: 7.2859 - acc: 0.4922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t 22/254 [=>............................] - ETA: 17s - loss: 1.2516 - acc: 0.6637 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t 41/254 [===>..........................] - ETA: 9s - loss: 0.9090 - acc: 0.7066 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 5s - loss: 0.7591 - acc: 0.7380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t 78/254 [========>.....................] - ETA: 4s - loss: 0.6896 - acc: 0.7501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t 98/254 [==========>...................] - ETA: 3s - loss: 0.6401 - acc: 0.7585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t118/254 [============>.................] - ETA: 2s - loss: 0.6048 - acc: 0.7666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t138/254 [===============>..............] - ETA: 1s - loss: 0.5806 - acc: 0.7712\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t157/254 [=================>............] - ETA: 1s - loss: 0.5605 - acc: 0.7769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.5443 - acc: 0.7810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:40 +0000\tmaster-replica-0\t\t195/254 [======================>.......] - ETA: 0s - loss: 0.5331 - acc: 0.7830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t215/254 [========================>.....] - ETA: 0s - loss: 0.5199 - acc: 0.7857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t235/254 [==========================>...] - ETA: 0s - loss: 0.5105 - acc: 0.7876\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t254/254 [==============================] - 3s 10ms/step - loss: 0.5014 - acc: 0.7898 - val_loss: 0.3776 - val_acc: 0.8292\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\tEpoch 2/20\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3205 - acc: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t 22/254 [=>............................] - ETA: 0s - loss: 0.3596 - acc: 0.8381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t 42/254 [===>..........................] - ETA: 0s - loss: 0.3618 - acc: 0.8365\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t 63/254 [======>.......................] - ETA: 0s - loss: 0.3641 - acc: 0.8353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t 84/254 [========>.....................] - ETA: 0s - loss: 0.3610 - acc: 0.8373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 0.3599 - acc: 0.8374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t125/254 [=============>................] - ETA: 0s - loss: 0.3608 - acc: 0.8360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t146/254 [================>.............] - ETA: 0s - loss: 0.3593 - acc: 0.8367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t166/254 [==================>...........] - ETA: 0s - loss: 0.3584 - acc: 0.8373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t187/254 [=====================>........] - ETA: 0s - loss: 0.3584 - acc: 0.8369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:41 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3594 - acc: 0.8361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t228/254 [=========================>....] - ETA: 0s - loss: 0.3587 - acc: 0.8363\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t248/254 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3596 - acc: 0.8361 - val_loss: 0.3398 - val_acc: 0.8411\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\tEpoch 3/20\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3509 - acc: 0.8203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3298 - acc: 0.8511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t 38/254 [===>..........................] - ETA: 0s - loss: 0.3311 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t 58/254 [=====>........................] - ETA: 0s - loss: 0.3385 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t 78/254 [========>.....................] - ETA: 0s - loss: 0.3396 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t 99/254 [==========>...................] - ETA: 0s - loss: 0.3408 - acc: 0.8454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t121/254 [=============>................] - ETA: 0s - loss: 0.3417 - acc: 0.8446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t141/254 [===============>..............] - ETA: 0s - loss: 0.3416 - acc: 0.8451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t162/254 [==================>...........] - ETA: 0s - loss: 0.3446 - acc: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t183/254 [====================>.........] - ETA: 0s - loss: 0.3431 - acc: 0.8432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:42 +0000\tmaster-replica-0\t\t201/254 [======================>.......] - ETA: 0s - loss: 0.3420 - acc: 0.8434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t222/254 [=========================>....] - ETA: 0s - loss: 0.3438 - acc: 0.8427\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t243/254 [===========================>..] - ETA: 0s - loss: 0.3422 - acc: 0.8437\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3420 - acc: 0.8438 - val_loss: 0.3252 - val_acc: 0.8507\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\tEpoch 4/20\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3034 - acc: 0.8594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3332 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3369 - acc: 0.8454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t 56/254 [=====>........................] - ETA: 0s - loss: 0.3288 - acc: 0.8474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t 76/254 [=======>......................] - ETA: 0s - loss: 0.3334 - acc: 0.8462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t 96/254 [==========>...................] - ETA: 0s - loss: 0.3314 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t117/254 [============>.................] - ETA: 0s - loss: 0.3367 - acc: 0.8455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3371 - acc: 0.8460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t155/254 [=================>............] - ETA: 0s - loss: 0.3383 - acc: 0.8448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.3380 - acc: 0.8443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t196/254 [======================>.......] - ETA: 0s - loss: 0.3357 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:43 +0000\tmaster-replica-0\t\t217/254 [========================>.....] - ETA: 0s - loss: 0.3360 - acc: 0.8439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t238/254 [===========================>..] - ETA: 0s - loss: 0.3370 - acc: 0.8437\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3361 - acc: 0.8437 - val_loss: 0.3255 - val_acc: 0.8441\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\tEpoch 5/20\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2531 - acc: 0.8828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t 21/254 [=>............................] - ETA: 0s - loss: 0.3167 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3266 - acc: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3284 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t 80/254 [========>.....................] - ETA: 0s - loss: 0.3284 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t101/254 [==========>...................] - ETA: 0s - loss: 0.3286 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t121/254 [=============>................] - ETA: 0s - loss: 0.3295 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t142/254 [===============>..............] - ETA: 0s - loss: 0.3311 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t160/254 [=================>............] - ETA: 0s - loss: 0.3312 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t181/254 [====================>.........] - ETA: 0s - loss: 0.3311 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t201/254 [======================>.......] - ETA: 0s - loss: 0.3341 - acc: 0.8474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:44 +0000\tmaster-replica-0\t\t223/254 [=========================>....] - ETA: 0s - loss: 0.3334 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t243/254 [===========================>..] - ETA: 0s - loss: 0.3329 - acc: 0.8466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3339 - acc: 0.8460 - val_loss: 0.3226 - val_acc: 0.8478\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\tEpoch 6/20\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3432 - acc: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3338 - acc: 0.8384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3406 - acc: 0.8393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3386 - acc: 0.8404\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t 82/254 [========>.....................] - ETA: 0s - loss: 0.3345 - acc: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3378 - acc: 0.8423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t124/254 [=============>................] - ETA: 0s - loss: 0.3342 - acc: 0.8436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t145/254 [================>.............] - ETA: 0s - loss: 0.3334 - acc: 0.8451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t167/254 [==================>...........] - ETA: 0s - loss: 0.3333 - acc: 0.8463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t186/254 [====================>.........] - ETA: 0s - loss: 0.3311 - acc: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t207/254 [=======================>......] - ETA: 0s - loss: 0.3318 - acc: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:45 +0000\tmaster-replica-0\t\t227/254 [=========================>....] - ETA: 0s - loss: 0.3309 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t248/254 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3317 - acc: 0.8466 - val_loss: 0.3267 - val_acc: 0.8469\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\tEpoch 7/20\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2504 - acc: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t 21/254 [=>............................] - ETA: 0s - loss: 0.3170 - acc: 0.8557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t 41/254 [===>..........................] - ETA: 0s - loss: 0.3079 - acc: 0.8571\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3188 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t 82/254 [========>.....................] - ETA: 0s - loss: 0.3229 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t100/254 [==========>...................] - ETA: 0s - loss: 0.3236 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t117/254 [============>.................] - ETA: 0s - loss: 0.3255 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t132/254 [==============>...............] - ETA: 0s - loss: 0.3274 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t151/254 [================>.............] - ETA: 0s - loss: 0.3275 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t169/254 [==================>...........] - ETA: 0s - loss: 0.3278 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t187/254 [=====================>........] - ETA: 0s - loss: 0.3285 - acc: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t203/254 [======================>.......] - ETA: 0s - loss: 0.3269 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:46 +0000\tmaster-replica-0\t\t221/254 [=========================>....] - ETA: 0s - loss: 0.3268 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3266 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t253/254 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3281 - acc: 0.8488 - val_loss: 0.3253 - val_acc: 0.8507\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\tEpoch 8/20\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3312 - acc: 0.8359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3337 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t 35/254 [===>..........................] - ETA: 0s - loss: 0.3359 - acc: 0.8462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t 52/254 [=====>........................] - ETA: 0s - loss: 0.3368 - acc: 0.8447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t 66/254 [======>.......................] - ETA: 0s - loss: 0.3386 - acc: 0.8432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t 85/254 [=========>....................] - ETA: 0s - loss: 0.3355 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3305 - acc: 0.8471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t120/254 [=============>................] - ETA: 0s - loss: 0.3330 - acc: 0.8451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t138/254 [===============>..............] - ETA: 0s - loss: 0.3312 - acc: 0.8453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t155/254 [=================>............] - ETA: 0s - loss: 0.3304 - acc: 0.8456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t171/254 [===================>..........] - ETA: 0s - loss: 0.3302 - acc: 0.8469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t190/254 [=====================>........] - ETA: 0s - loss: 0.3296 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:47 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3291 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t225/254 [=========================>....] - ETA: 0s - loss: 0.3289 - acc: 0.8466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t243/254 [===========================>..] - ETA: 0s - loss: 0.3295 - acc: 0.8465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3292 - acc: 0.8469 - val_loss: 0.3288 - val_acc: 0.8449\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\tEpoch 9/20\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2406 - acc: 0.8828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3321 - acc: 0.8405\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3356 - acc: 0.8432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t 56/254 [=====>........................] - ETA: 0s - loss: 0.3361 - acc: 0.8422\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t 76/254 [=======>......................] - ETA: 0s - loss: 0.3278 - acc: 0.8483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t 94/254 [==========>...................] - ETA: 0s - loss: 0.3334 - acc: 0.8462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t114/254 [============>.................] - ETA: 0s - loss: 0.3308 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t130/254 [==============>...............] - ETA: 0s - loss: 0.3295 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t150/254 [================>.............] - ETA: 0s - loss: 0.3280 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t169/254 [==================>...........] - ETA: 0s - loss: 0.3284 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:48 +0000\tmaster-replica-0\t\t189/254 [=====================>........] - ETA: 0s - loss: 0.3273 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3277 - acc: 0.8493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t226/254 [=========================>....] - ETA: 0s - loss: 0.3272 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t245/254 [===========================>..] - ETA: 0s - loss: 0.3283 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3284 - acc: 0.8483 - val_loss: 0.3220 - val_acc: 0.8494\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\tEpoch 10/20\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3634 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3450 - acc: 0.8466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3335 - acc: 0.8469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3279 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t 77/254 [========>.....................] - ETA: 0s - loss: 0.3284 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t 97/254 [==========>...................] - ETA: 0s - loss: 0.3318 - acc: 0.8455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t114/254 [============>.................] - ETA: 0s - loss: 0.3318 - acc: 0.8463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t133/254 [==============>...............] - ETA: 0s - loss: 0.3306 - acc: 0.8475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t152/254 [================>.............] - ETA: 0s - loss: 0.3301 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t172/254 [===================>..........] - ETA: 0s - loss: 0.3300 - acc: 0.8465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:49 +0000\tmaster-replica-0\t\t190/254 [=====================>........] - ETA: 0s - loss: 0.3290 - acc: 0.8474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t210/254 [=======================>......] - ETA: 0s - loss: 0.3287 - acc: 0.8471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t229/254 [==========================>...] - ETA: 0s - loss: 0.3292 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t249/254 [============================>.] - ETA: 0s - loss: 0.3294 - acc: 0.8470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3286 - acc: 0.8476 - val_loss: 0.3231 - val_acc: 0.8511\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\tEpoch 11/20\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3206 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t  2/254 [..............................] - ETA: 7s - loss: 0.3187 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 1s - loss: 0.3188 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3165 - acc: 0.8532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t 58/254 [=====>........................] - ETA: 0s - loss: 0.3237 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t 76/254 [=======>......................] - ETA: 0s - loss: 0.3198 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t 95/254 [==========>...................] - ETA: 0s - loss: 0.3201 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t112/254 [============>.................] - ETA: 0s - loss: 0.3218 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t131/254 [==============>...............] - ETA: 0s - loss: 0.3213 - acc: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:50 +0000\tmaster-replica-0\t\t150/254 [================>.............] - ETA: 0s - loss: 0.3213 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t169/254 [==================>...........] - ETA: 0s - loss: 0.3216 - acc: 0.8513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t188/254 [=====================>........] - ETA: 0s - loss: 0.3242 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t209/254 [=======================>......] - ETA: 0s - loss: 0.3244 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t229/254 [==========================>...] - ETA: 0s - loss: 0.3255 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t249/254 [============================>.] - ETA: 0s - loss: 0.3262 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3270 - acc: 0.8497 - val_loss: 0.3224 - val_acc: 0.8475\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.010004882812500001.\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\tEpoch 12/20\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2845 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3328 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3129 - acc: 0.8598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t 57/254 [=====>........................] - ETA: 0s - loss: 0.3140 - acc: 0.8575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t 77/254 [========>.....................] - ETA: 0s - loss: 0.3181 - acc: 0.8534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t 97/254 [==========>...................] - ETA: 0s - loss: 0.3177 - acc: 0.8541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t116/254 [============>.................] - ETA: 0s - loss: 0.3198 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t135/254 [==============>...............] - ETA: 0s - loss: 0.3220 - acc: 0.8514\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:51 +0000\tmaster-replica-0\t\t155/254 [=================>............] - ETA: 0s - loss: 0.3216 - acc: 0.8514\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t173/254 [===================>..........] - ETA: 0s - loss: 0.3248 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t193/254 [=====================>........] - ETA: 0s - loss: 0.3250 - acc: 0.8498\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t212/254 [========================>.....] - ETA: 0s - loss: 0.3233 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t233/254 [==========================>...] - ETA: 0s - loss: 0.3239 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t252/254 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3255 - acc: 0.8491 - val_loss: 0.3386 - val_acc: 0.8396\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\tEpoch 13/20\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2794 - acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t 21/254 [=>............................] - ETA: 0s - loss: 0.3147 - acc: 0.8460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t 42/254 [===>..........................] - ETA: 0s - loss: 0.3219 - acc: 0.8423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3155 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t 82/254 [========>.....................] - ETA: 0s - loss: 0.3172 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3173 - acc: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t123/254 [=============>................] - ETA: 0s - loss: 0.3202 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t142/254 [===============>..............] - ETA: 0s - loss: 0.3201 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:52 +0000\tmaster-replica-0\t\t161/254 [==================>...........] - ETA: 0s - loss: 0.3220 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t180/254 [====================>.........] - ETA: 0s - loss: 0.3225 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t200/254 [======================>.......] - ETA: 0s - loss: 0.3223 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t221/254 [=========================>....] - ETA: 0s - loss: 0.3214 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t240/254 [===========================>..] - ETA: 0s - loss: 0.3219 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3229 - acc: 0.8503 - val_loss: 0.3207 - val_acc: 0.8527\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\tEpoch 14/20\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2922 - acc: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3391 - acc: 0.8446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t 37/254 [===>..........................] - ETA: 0s - loss: 0.3384 - acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t 54/254 [=====>........................] - ETA: 0s - loss: 0.3287 - acc: 0.8436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t 73/254 [=======>......................] - ETA: 0s - loss: 0.3239 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t 88/254 [=========>....................] - ETA: 0s - loss: 0.3271 - acc: 0.8456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t107/254 [===========>..................] - ETA: 0s - loss: 0.3240 - acc: 0.8468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t127/254 [==============>...............] - ETA: 0s - loss: 0.3225 - acc: 0.8468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:53 +0000\tmaster-replica-0\t\t146/254 [================>.............] - ETA: 0s - loss: 0.3250 - acc: 0.8461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t164/254 [==================>...........] - ETA: 0s - loss: 0.3249 - acc: 0.8454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t184/254 [====================>.........] - ETA: 0s - loss: 0.3255 - acc: 0.8448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t201/254 [======================>.......] - ETA: 0s - loss: 0.3243 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t218/254 [========================>.....] - ETA: 0s - loss: 0.3227 - acc: 0.8470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t235/254 [==========================>...] - ETA: 0s - loss: 0.3224 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3224 - acc: 0.8479 - val_loss: 0.3239 - val_acc: 0.8543\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\tEpoch 15/20\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.4470 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 0s - loss: 0.3506 - acc: 0.8434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t 41/254 [===>..........................] - ETA: 0s - loss: 0.3376 - acc: 0.8457\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t 60/254 [======>.......................] - ETA: 0s - loss: 0.3290 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t 80/254 [========>.....................] - ETA: 0s - loss: 0.3213 - acc: 0.8528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t100/254 [==========>...................] - ETA: 0s - loss: 0.3207 - acc: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t118/254 [============>.................] - ETA: 0s - loss: 0.3226 - acc: 0.8526\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t138/254 [===============>..............] - ETA: 0s - loss: 0.3239 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:54 +0000\tmaster-replica-0\t\t155/254 [=================>............] - ETA: 0s - loss: 0.3231 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.3251 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t192/254 [=====================>........] - ETA: 0s - loss: 0.3236 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t212/254 [========================>.....] - ETA: 0s - loss: 0.3241 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t232/254 [==========================>...] - ETA: 0s - loss: 0.3263 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t252/254 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3245 - acc: 0.8494 - val_loss: 0.3276 - val_acc: 0.8523\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.01000030517578125.\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\tEpoch 16/20\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3814 - acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t 17/254 [=>............................] - ETA: 0s - loss: 0.3339 - acc: 0.8415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t 36/254 [===>..........................] - ETA: 0s - loss: 0.3299 - acc: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t 55/254 [=====>........................] - ETA: 0s - loss: 0.3249 - acc: 0.8533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t 76/254 [=======>......................] - ETA: 0s - loss: 0.3262 - acc: 0.8521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t 95/254 [==========>...................] - ETA: 0s - loss: 0.3268 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t116/254 [============>.................] - ETA: 0s - loss: 0.3290 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3293 - acc: 0.8474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:55 +0000\tmaster-replica-0\t\t154/254 [=================>............] - ETA: 0s - loss: 0.3273 - acc: 0.8471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t171/254 [===================>..........] - ETA: 0s - loss: 0.3264 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t191/254 [=====================>........] - ETA: 0s - loss: 0.3254 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t209/254 [=======================>......] - ETA: 0s - loss: 0.3249 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t229/254 [==========================>...] - ETA: 0s - loss: 0.3242 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t246/254 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3231 - acc: 0.8504 - val_loss: 0.3165 - val_acc: 0.8527\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.010000152587890625.\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\tEpoch 17/20\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3580 - acc: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t  2/254 [..............................] - ETA: 6s - loss: 0.4006 - acc: 0.8086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t 21/254 [=>............................] - ETA: 1s - loss: 0.3471 - acc: 0.8374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t 41/254 [===>..........................] - ETA: 0s - loss: 0.3338 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3247 - acc: 0.8545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t 81/254 [========>.....................] - ETA: 0s - loss: 0.3211 - acc: 0.8533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3213 - acc: 0.8523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:56 +0000\tmaster-replica-0\t\t120/254 [=============>................] - ETA: 0s - loss: 0.3239 - acc: 0.8512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t140/254 [===============>..............] - ETA: 0s - loss: 0.3265 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t159/254 [=================>............] - ETA: 0s - loss: 0.3254 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t178/254 [====================>.........] - ETA: 0s - loss: 0.3251 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t197/254 [======================>.......] - ETA: 0s - loss: 0.3253 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t218/254 [========================>.....] - ETA: 0s - loss: 0.3260 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3246 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3228 - acc: 0.8496 - val_loss: 0.3245 - val_acc: 0.8481\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.010000076293945313.\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\tEpoch 18/20\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3317 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 0s - loss: 0.3305 - acc: 0.8410\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3228 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3214 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3191 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t 98/254 [==========>...................] - ETA: 0s - loss: 0.3205 - acc: 0.8521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:57 +0000\tmaster-replica-0\t\t118/254 [============>.................] - ETA: 0s - loss: 0.3234 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t138/254 [===============>..............] - ETA: 0s - loss: 0.3214 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t157/254 [=================>............] - ETA: 0s - loss: 0.3217 - acc: 0.8515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t176/254 [===================>..........] - ETA: 0s - loss: 0.3215 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t196/254 [======================>.......] - ETA: 0s - loss: 0.3204 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t216/254 [========================>.....] - ETA: 0s - loss: 0.3224 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t234/254 [==========================>...] - ETA: 0s - loss: 0.3223 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3220 - acc: 0.8509 - val_loss: 0.3214 - val_acc: 0.8516\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.010000038146972657.\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\tEpoch 19/20\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3147 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t  7/254 [..............................] - ETA: 1s - loss: 0.3151 - acc: 0.8493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t 27/254 [==>...........................] - ETA: 0s - loss: 0.3267 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t 46/254 [====>.........................] - ETA: 0s - loss: 0.3195 - acc: 0.8507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t 65/254 [======>.......................] - ETA: 0s - loss: 0.3160 - acc: 0.8524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:58 +0000\tmaster-replica-0\t\t 85/254 [=========>....................] - ETA: 0s - loss: 0.3200 - acc: 0.8523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 0.3188 - acc: 0.8534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t125/254 [=============>................] - ETA: 0s - loss: 0.3200 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t144/254 [================>.............] - ETA: 0s - loss: 0.3216 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t164/254 [==================>...........] - ETA: 0s - loss: 0.3228 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t185/254 [====================>.........] - ETA: 0s - loss: 0.3225 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t205/254 [=======================>......] - ETA: 0s - loss: 0.3229 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t225/254 [=========================>....] - ETA: 0s - loss: 0.3209 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t243/254 [===========================>..] - ETA: 0s - loss: 0.3219 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3227 - acc: 0.8493 - val_loss: 0.3301 - val_acc: 0.8470\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.010000019073486329.\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\tEpoch 20/20\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2615 - acc: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t 22/254 [=>............................] - ETA: 0s - loss: 0.3162 - acc: 0.8551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t 44/254 [====>.........................] - ETA: 0s - loss: 0.3207 - acc: 0.8525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t 64/254 [======>.......................] - ETA: 0s - loss: 0.3211 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t 81/254 [========>.....................] - ETA: 0s - loss: 0.3175 - acc: 0.8536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:42:59 +0000\tmaster-replica-0\t\t101/254 [==========>...................] - ETA: 0s - loss: 0.3158 - acc: 0.8546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t122/254 [=============>................] - ETA: 0s - loss: 0.3192 - acc: 0.8535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t142/254 [===============>..............] - ETA: 0s - loss: 0.3195 - acc: 0.8530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t163/254 [==================>...........] - ETA: 0s - loss: 0.3185 - acc: 0.8534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t184/254 [====================>.........] - ETA: 0s - loss: 0.3191 - acc: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3193 - acc: 0.8532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t228/254 [=========================>....] - ETA: 0s - loss: 0.3200 - acc: 0.8529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t249/254 [============================>.] - ETA: 0s - loss: 0.3232 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "INFO\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3226 - acc: 0.8522 - val_loss: 0.3399 - val_acc: 0.8502\n",
            "WARNING\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\tFrom /root/.local/lib/python3.7/site-packages/trainer/task.py:123: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:43:00 +0000\tmaster-replica-0\t\tPlease use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tCall initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:43:03 +0000\tmaster-replica-0\t\tCall initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "WARNING\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
            "WARNING\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: None\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: ['train']\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
            "WARNING\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tExport includes no default signature!\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tNo assets to save.\n",
            "INFO\t2021-06-19 17:43:08 +0000\tmaster-replica-0\t\tNo assets to write.\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: None\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tExport includes no default signature!\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tNo assets to save.\n",
            "INFO\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tNo assets to write.\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING\t2021-06-19 17:43:10 +0000\tmaster-replica-0\t\tA checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tNo assets to save.\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tNo assets to write.\n",
            "INFO\t2021-06-19 17:43:11 +0000\tmaster-replica-0\t\tSavedModel written to: gs://nooji-test-bucket/keras-job-dir/keras_export/saved_model.pb\n",
            "INFO\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tModel exported to: gs://nooji-test-bucket/keras-job-dir/keras_export\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tUnresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tA checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
            "INFO\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tClean up finished.\n",
            "INFO\t2021-06-19 17:43:12 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
            "INFO\t2021-06-19 17:45:30 +0000\tservice\t\tJob completed successfully.\n",
            "endTime: '2021-06-19T17:45:30'\n",
            "jobId: nooji_4B_keras_job\n",
            "startTime: '2021-06-19T17:42:28'\n",
            "state: SUCCEEDED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gAO6-zv6osJ8"
      },
      "source": [
        "# Part 2 (Cloud Deployment). Quickstart for online predictions in AI Platform\n",
        "\n",
        "This section shows how to use AI Platform and your trained model from Part 1\n",
        "to predict a person's income bracket from other Census information about them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Oi1xMGzLsjf_"
      },
      "source": [
        "### Create model and version resources in AI Platform\n",
        "\n",
        "To serve online predictions using the model you trained and exported in Part 1,\n",
        "create a *model* resource in AI Platform and a *version* resource\n",
        "within it. The version resource is what actually uses your trained model to\n",
        "serve predictions. This structure lets you adjust and retrain your model many times and\n",
        "organize all the versions together in AI Platform. Learn more about [models\n",
        "and\n",
        "versions](https://cloud.google.com/ml-engine/docs/tensorflow/projects-models-versions-jobs).\n",
        "\n",
        "First, name and create the model resource:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SurMKEbBtc2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e0af47-ebe3-4272-9a9d-7a9a936fe05c"
      },
      "source": [
        "############ENTER HERE#########################\n",
        "MODEL_NAME = \"nooji_Keras_model \" #<Lastname_Keras_model>\n",
        "\n",
        "! gcloud ai-platform models create $MODEL_NAME \\\n",
        "  --region $REGION"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-east1-ml.googleapis.com/]\n",
            "Created ai platform model [projects/fb-mle-march-21/models/nooji_Keras_model].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTWnbT2UewTZ",
        "outputId": "06c38230-1a13-43b1-ca22-6ad51f8447a7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hptuning_config.yaml   README.md\t scripts\n",
            "local-training-output  requirements.txt  trainer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "c5YLJugmt-Wm"
      },
      "source": [
        " # You can verify your job completion at the AI Training Dashboard:\n",
        " https://console.cloud.google.com/ai-platform/models/\n",
        "\n",
        " # Look under jobs and models on the left panel\n",
        "```\n",
        "\n",
        "Execute the following command to identify your SavedModel directory and use it to create a model version resource:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3mtBIAcoXku",
        "outputId": "c2ccc813-a68e-4552-941f-377dafb4cda3"
      },
      "source": [
        "#ENTER HERE#####################\n",
        "MODEL_VERSION = \"v_nooji\" # Give a unique name <v_Lastname>\n",
        "\n",
        "# Get a list of directories in the `keras_export` parent directory\n",
        "KERAS_EXPORT_DIRS = ! gsutil ls $JOB_DIR/keras_export/\n",
        "print(KERAS_EXPORT_DIRS)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://nooji-test-bucket/keras-job-dir/keras_export/', 'gs://nooji-test-bucket/keras-job-dir/keras_export/saved_model.pb', 'gs://nooji-test-bucket/keras-job-dir/keras_export/assets/', 'gs://nooji-test-bucket/keras-job-dir/keras_export/variables/']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhDlqAXaoow9",
        "outputId": "6c81bd11-7334-4261-df50-b931c5668aa9"
      },
      "source": [
        "# Point to the folder ../keras_export. Your index number may be different that the one here based on how many times you ahve run.\n",
        "idx=0\n",
        "SAVED_MODEL_PATH = KERAS_EXPORT_DIRS[idx]\n",
        "print(SAVED_MODEL_PATH)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://nooji-test-bucket/keras-job-dir/keras_export/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv436o5Eo0eO",
        "outputId": "05f3954c-56fb-4b72-a83c-2c6ff299619a"
      },
      "source": [
        "print(MODEL_NAME)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nooji_Keras_model \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "deletable": true,
        "editable": true,
        "id": "NYfK78654CVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f8cfdd-7950-42a0-a815-03a363c7d1c0"
      },
      "source": [
        "# Create model version based on that SavedModel directory\n",
        "! gcloud ai-platform versions create $MODEL_VERSION \\\n",
        "  --model $MODEL_NAME \\\n",
        "  --region $REGION \\\n",
        "  --runtime-version 1.15 \\\n",
        "  --python-version 3.7 \\\n",
        "  --framework tensorflow \\\n",
        "  --origin $SAVED_MODEL_PATH"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-east1-ml.googleapis.com/]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQUEdzroNJgB"
      },
      "source": [
        "# Now you are ready to submit a training job to Google AI platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JzevJps9IOcU"
      },
      "source": [
        "# Task 2: Data Preparation for Modeling\n",
        "\n",
        "To receive valid and useful predictions, you must preprocess input for prediction in the same way that training data was preprocessed. In a production\n",
        "system, you may want to create a preprocessing pipeline that can be used identically at training time and prediction time.\n",
        "\n",
        "For this exercise, use the training package's data-loading code to select a random sample from the evaluation data. This data is in the form that was used to evaluate accuracy after each epoch of training, so it can be used to send test predictions without further preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zuh7LWeWv_GT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "3964435f-392b-4e2b-f734-65a74fa0cf75"
      },
      "source": [
        "#First, lets review the data and features that are used for classifictaion\n",
        "from trainer import util\n",
        "\n",
        "_, _, eval_x, eval_y = util.load_data()\n",
        "\n",
        "prediction_input = eval_x.sample(20)\n",
        "prediction_targets = eval_y[prediction_input.index]\n",
        "\n",
        "prediction_input"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>-0.411611</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.030304</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1712</th>\n",
              "      <td>-0.484546</td>\n",
              "      <td>4</td>\n",
              "      <td>1.525542</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.934372</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>0.536539</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.030304</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.195441</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>-0.192807</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>1.047082</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.419265</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.437544</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7018</th>\n",
              "      <td>-0.703350</td>\n",
              "      <td>3</td>\n",
              "      <td>1.525542</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9915</th>\n",
              "      <td>-0.557481</td>\n",
              "      <td>3</td>\n",
              "      <td>1.525542</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>4.502280</td>\n",
              "      <td>0.369465</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14091</th>\n",
              "      <td>-0.630415</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.419265</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>1.176475</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>-0.484546</td>\n",
              "      <td>6</td>\n",
              "      <td>1.525542</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15588</th>\n",
              "      <td>-0.922154</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15817</th>\n",
              "      <td>-0.703350</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4169</th>\n",
              "      <td>-0.922154</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.369465</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13439</th>\n",
              "      <td>-1.213893</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.419265</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.841048</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9092</th>\n",
              "      <td>0.171866</td>\n",
              "      <td>3</td>\n",
              "      <td>0.358658</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.127363</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582</th>\n",
              "      <td>0.901213</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.030304</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.772970</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>0.098931</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.772970</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>1.338821</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.197188</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3575</th>\n",
              "      <td>0.609474</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>0.772970</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16164</th>\n",
              "      <td>-0.776285</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.030304</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7167</th>\n",
              "      <td>-0.557481</td>\n",
              "      <td>3</td>\n",
              "      <td>0.358658</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.841048</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  workclass  ...  hours_per_week  native_country\n",
              "2597  -0.411611          6  ...       -0.034039              38\n",
              "1712  -0.484546          4  ...        0.934372              38\n",
              "7269   0.536539          3  ...       -0.195441              38\n",
              "1895  -0.192807          3  ...       -0.034039              38\n",
              "274    1.047082         -1  ...       -0.437544              38\n",
              "7018  -0.703350          3  ...       -0.034039              38\n",
              "9915  -0.557481          3  ...        0.369465              38\n",
              "14091 -0.630415          3  ...        1.176475              38\n",
              "3147  -0.484546          6  ...       -0.034039              38\n",
              "15588 -0.922154          3  ...       -0.034039              38\n",
              "15817 -0.703350          3  ...       -0.034039              38\n",
              "4169  -0.922154          3  ...        0.369465              38\n",
              "13439 -1.213893         -1  ...       -0.841048              38\n",
              "9092   0.171866          3  ...        0.127363              38\n",
              "4582   0.901213          3  ...        0.772970              38\n",
              "2124   0.098931          3  ...        0.772970              38\n",
              "2402   1.338821          3  ...       -0.034039              38\n",
              "3575   0.609474          3  ...        0.772970              38\n",
              "16164 -0.776285          3  ...       -0.034039              38\n",
              "7167  -0.557481          3  ...       -0.841048              38\n",
              "\n",
              "[20 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HV1JhIWkn1t5"
      },
      "source": [
        "Notice that categorical fields, like `occupation`,  have already been converted to integers (with the same mapping that was used for training). Numerical fields, like `age`, have been scaled to a\n",
        "[z-score](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data). Some fields have been dropped from the original\n",
        "data. Compare the prediction input with the raw data for the same examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fvRzpDgugqQr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "0ba67069-ddcc-4e40-9c8c-6ae6303c7ad0"
      },
      "source": [
        "#Now lets review the raw data with all features\n",
        "import pandas as pd\n",
        "\n",
        "_, eval_file_path = util.download(util.DATA_DIR)\n",
        "raw_eval_data = pd.read_csv(eval_file_path,\n",
        "                            names=util._CSV_COLUMNS,\n",
        "                            na_values='?')\n",
        "\n",
        "raw_eval_data.iloc[prediction_input.index]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>33</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>237903</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1712</th>\n",
              "      <td>32</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>235847</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>46</td>\n",
              "      <td>Private</td>\n",
              "      <td>114120</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>36</td>\n",
              "      <td>Private</td>\n",
              "      <td>50707</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Priv-house-serv</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>237868</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7018</th>\n",
              "      <td>29</td>\n",
              "      <td>Private</td>\n",
              "      <td>354496</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9915</th>\n",
              "      <td>31</td>\n",
              "      <td>Private</td>\n",
              "      <td>181388</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>1902</td>\n",
              "      <td>45</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14091</th>\n",
              "      <td>30</td>\n",
              "      <td>Private</td>\n",
              "      <td>155914</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>32</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>316589</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15588</th>\n",
              "      <td>26</td>\n",
              "      <td>Private</td>\n",
              "      <td>235520</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15817</th>\n",
              "      <td>29</td>\n",
              "      <td>Private</td>\n",
              "      <td>85572</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4169</th>\n",
              "      <td>26</td>\n",
              "      <td>Private</td>\n",
              "      <td>157617</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13439</th>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>205940</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9092</th>\n",
              "      <td>41</td>\n",
              "      <td>Private</td>\n",
              "      <td>29591</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582</th>\n",
              "      <td>51</td>\n",
              "      <td>Private</td>\n",
              "      <td>275507</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>53956</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>57</td>\n",
              "      <td>Private</td>\n",
              "      <td>190488</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3575</th>\n",
              "      <td>47</td>\n",
              "      <td>Private</td>\n",
              "      <td>216999</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16164</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>249720</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7167</th>\n",
              "      <td>31</td>\n",
              "      <td>Private</td>\n",
              "      <td>192660</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age     workclass  fnlwgt  ... hours_per_week  native_country income_bracket\n",
              "2597    33     State-gov  237903  ...             40   United-States          <=50K\n",
              "1712    32  Self-emp-inc  235847  ...             52   United-States          <=50K\n",
              "7269    46       Private  114120  ...             38   United-States          <=50K\n",
              "1895    36       Private   50707  ...             40   United-States          <=50K\n",
              "274     53           NaN  237868  ...             35   United-States           >50K\n",
              "7018    29       Private  354496  ...             40   United-States          <=50K\n",
              "9915    31       Private  181388  ...             45   United-States           >50K\n",
              "14091   30       Private  155914  ...             55   United-States          <=50K\n",
              "3147    32     State-gov  316589  ...             40   United-States           >50K\n",
              "15588   26       Private  235520  ...             40   United-States           >50K\n",
              "15817   29       Private   85572  ...             40   United-States          <=50K\n",
              "4169    26       Private  157617  ...             45   United-States          <=50K\n",
              "13439   22           NaN  205940  ...             30   United-States          <=50K\n",
              "9092    41       Private   29591  ...             42   United-States          <=50K\n",
              "4582    51       Private  275507  ...             50   United-States          <=50K\n",
              "2124    40       Private   53956  ...             50   United-States          <=50K\n",
              "2402    57       Private  190488  ...             40   United-States           >50K\n",
              "3575    47       Private  216999  ...             50   United-States          <=50K\n",
              "16164   28       Private  249720  ...             40   United-States          <=50K\n",
              "7167    31       Private  192660  ...             30   United-States          <=50K\n",
              "\n",
              "[20 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HFAbbH6ksG6s"
      },
      "source": [
        "Export the prediction input (filtered features only) to a newline-delimited JSON file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Yl3JALtnsGj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f65d18f-5337-4d33-da88-27515465e544"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('prediction_input.json', 'w') as json_file:\n",
        "  for row in prediction_input.values.tolist():\n",
        "    json.dump(row, json_file)\n",
        "    json_file.write('\\n')\n",
        "\n",
        "! cat prediction_input.json"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.4116113873310685, 6.0, -0.030303770229214273, 0.0, 9.0, 1.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.48454606302320563, 4.0, 1.525541514460902, 4.0, 3.0, 1.0, 4.0, -0.14479173735784842, -0.21713186390175285, 0.934371839987696, 38.0]\n",
            "[0.5365393966667138, 3.0, -0.030303770229214273, 0.0, 12.0, 1.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.19544108326612056, 38.0]\n",
            "[-0.19280736025465722, 3.0, 1.1365801932883728, 0.0, 8.0, 4.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[1.0470821265116736, -1.0, -0.4192650914017433, 2.0, -1.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.43754385253479555, 38.0]\n",
            "[-0.7033500900996169, 3.0, 1.525541514460902, 4.0, 9.0, 1.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.5574807387153428, 3.0, 1.525541514460902, 2.0, 9.0, 5.0, 4.0, -0.14479173735784842, 4.5022796885373735, 0.3694653783607877, 38.0]\n",
            "[-0.6304154144074798, 3.0, -0.4192650914017433, 2.0, 2.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, 1.176474609256371, 38.0]\n",
            "[-0.48454606302320563, 6.0, 1.525541514460902, 2.0, 3.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.9221541171760282, 3.0, 1.1365801932883728, 2.0, 0.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.7033500900996169, 3.0, 1.1365801932883728, 4.0, 3.0, 2.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.9221541171760282, 3.0, 1.1365801932883728, 4.0, 11.0, 3.0, 4.0, -0.14479173735784842, -0.21713186390175285, 0.3694653783607877, 38.0]\n",
            "[-1.2138928199445767, -1.0, -0.4192650914017433, 4.0, -1.0, 3.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.8410484679825871, 38.0]\n",
            "[0.17186601820602831, 3.0, 0.35865755094331475, 4.0, 2.0, 1.0, 4.0, -0.14479173735784842, -0.21713186390175285, 0.12736260909211275, 38.0]\n",
            "[0.9012127751273994, 3.0, -0.030303770229214273, 0.0, 11.0, 4.0, 2.0, -0.14479173735784842, -0.21713186390175285, 0.7729699938085793, 38.0]\n",
            "[0.0989313425138912, 3.0, 1.1365801932883728, 2.0, 9.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, 0.7729699938085793, 38.0]\n",
            "[1.338820829280222, 3.0, -1.1971877337468013, 2.0, 2.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[0.609474072358851, 3.0, 1.1365801932883728, 2.0, 3.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, 0.7729699938085793, 38.0]\n",
            "[-0.7762847657917541, 3.0, -0.030303770229214273, 2.0, 9.0, 0.0, 4.0, -0.14479173735784842, -0.21713186390175285, -0.03403923708700391, 38.0]\n",
            "[-0.5574807387153428, 3.0, 0.35865755094331475, 4.0, 0.0, 4.0, 2.0, -0.14479173735784842, -0.21713186390175285, -0.8410484679825871, 38.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kVvEmazFKUCp"
      },
      "source": [
        "The `gcloud` command-line tool accepts newline-delimited JSON for online\n",
        "prediction, and this particular Keras model expects a flat list of\n",
        "numbers for each input example.\n",
        "\n",
        "AI Platform requires a different format when you make online prediction requests to the REST API without using the `gcloud` tool. The way you structure\n",
        "your model may also change how you must format data for prediction. Learn more\n",
        "about [formatting data for online\n",
        "prediction](https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_input_data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "91xQnLqRN8A8"
      },
      "source": [
        "### Submit the online prediction request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KrDIoVLaG7zZ"
      },
      "source": [
        "Use `gcloud` to submit your online prediction request."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5gIcXDFwOERG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc4be43-c854-4e61-93d2-23cc05ec6e0c"
      },
      "source": [
        "! gcloud ai-platform predict \\\n",
        "  --model $MODEL_NAME \\\n",
        "  --region $REGION \\\n",
        "  --version $MODEL_VERSION \\\n",
        "  --json-instances prediction_input.json"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-east1-ml.googleapis.com/]\n",
            "[[0.00732091069], [0.150200039], [0.0156175792], [0.0247817338], [0.160367787], [0.0311962366], [0.77327764], [0.138848513], [0.348996609], [0.149517387], [0.00291228294], [0.00575524569], [7.74860382e-07], [0.0311662257], [0.022107631], [0.677194178], [0.120679103], [0.714982748], [0.0869566053], [0.00105022371]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "n6U2DYKJGwdf"
      },
      "source": [
        "Since the model's last layer uses a [sigmoid function](https://developers.google.com/machine-learning/glossary/#sigmoid_function) for its activation, outputs between 0 and 0.5 represent negative predictions (\"<=50K\") and outputs between 0.5 and 1 represent positive ones (\">50K\").\n",
        "\n",
        "Do the predicted income brackets match the actual ones? Run the following cell\n",
        "to see the true labels.\n",
        "# Q: How would you compute classification performance using the output json file above? Enter your answers below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "w2Piq3PcGhaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23574168-9d19-441f-97e2-44d9bacc074c"
      },
      "source": [
        "prediction_targets"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GKP7F6-EDb5_"
      },
      "source": [
        "## Part 3. Developing the Keras model from scratch\n",
        "\n",
        "At this point, you have trained a machine learning model on AI Platform, deployed the trained model as a version resource on AI Platform, and received online predictions from the deployment. The next section walks through recreating the Keras code used to train your model. It covers the following parts of developing a machine learning model for use with AI Platform:\n",
        "\n",
        "* Downloading and preprocessing data\n",
        "* Designing and training the model\n",
        "* Visualizing training and exporting the trained model\n",
        "\n",
        "# Now you will develop  a model from scratch and train on the same data by submitting a fresh job on the AI platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-VtUN0L5x4ql"
      },
      "source": [
        "### Import libraries and define constants\n",
        "\n",
        "First, import Python libraries required for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "RcxfR3GfscsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e90122-7cde-4359-e844-aeedffc347bc"
      },
      "source": [
        "import os\n",
        "from six.moves import urllib\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Examine software versions\n",
        "print(__import__('sys').version)\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "1.15.5\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "xWZQbZQmx26U"
      },
      "source": [
        "Then, define some useful constants:\n",
        "\n",
        "* Information for downloading training and evaluation data\n",
        "* Information required for Pandas to interpret the data and convert categorical fields into numeric features\n",
        "* Hyperparameters for training, such as learning rate and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Cx4OXeXEsh_v"
      },
      "source": [
        "### For downloading data ###\n",
        "\n",
        "# Storage directory\n",
        "DATA_DIR = os.path.join(tempfile.gettempdir(), 'census_data')\n",
        "\n",
        "# Download options.\n",
        "DATA_URL = 'https://storage.googleapis.com/cloud-samples-data/ai-platform' \\\n",
        "           '/census/data'\n",
        "TRAINING_FILE = 'adult.data.csv'\n",
        "EVAL_FILE = 'adult.test.csv'\n",
        "TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
        "EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)\n",
        "\n",
        "### For interpreting data ###\n",
        "\n",
        "# These are the features in the dataset.\n",
        "# Dataset information: https://archive.ics.uci.edu/ml/datasets/census+income\n",
        "_CSV_COLUMNS = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
        "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
        "    'income_bracket'\n",
        "]\n",
        "\n",
        "_CATEGORICAL_TYPES = {\n",
        "    'workclass': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc',\n",
        "        'Self-emp-not-inc', 'State-gov', 'Without-pay'\n",
        "    ]),\n",
        "    'marital_status': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
        "        'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'\n",
        "    ]),\n",
        "    'occupation': pd.api.types.CategoricalDtype([\n",
        "        'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial',\n",
        "        'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct',\n",
        "        'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv',\n",
        "        'Sales', 'Tech-support', 'Transport-moving'\n",
        "    ]),\n",
        "    'relationship': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried',\n",
        "        'Wife'\n",
        "    ]),\n",
        "    'race': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
        "    ]),\n",
        "    'native_country': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Cambodia', 'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic',\n",
        "        'Ecuador', 'El-Salvador', 'England', 'France', 'Germany', 'Greece',\n",
        "        'Guatemala', 'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary',\n",
        "        'India', 'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n",
        "        'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines', 'Poland',\n",
        "        'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand',\n",
        "        'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'\n",
        "    ]),\n",
        "    'income_bracket': pd.api.types.CategoricalDtype(categories=[\n",
        "        '<=50K', '>50K'\n",
        "    ])\n",
        "}\n",
        "\n",
        "# This is the label (target) we want to predict.\n",
        "_LABEL_COLUMN = 'income_bracket'\n",
        "\n",
        "### Hyperparameters for training ###\n",
        "\n",
        "# This the training batch size\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# This is the number of epochs (passes over the full training data)\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Define learning rate.\n",
        "LEARNING_RATE = .01"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bSJjhQ8ZyDae"
      },
      "source": [
        "### Download and preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uafupKCgxazq"
      },
      "source": [
        "#### Download the data\n",
        "\n",
        "Next, define functions to download training and evaluation data. These functions also fix minor irregularities in the data's formatting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "deletable": true,
        "editable": true,
        "id": "iGorBTXWUZPy"
      },
      "source": [
        "def _download_and_clean_file(filename, url):\n",
        "    \"\"\"Downloads data from url, and makes changes to match the CSV format.\n",
        "  \n",
        "    The CSVs may use spaces after the comma delimters (non-standard) or include\n",
        "    rows which do not represent well-formed examples. This function strips out\n",
        "    some of these problems.\n",
        "  \n",
        "    Args:\n",
        "      filename: filename to save url to\n",
        "      url: URL of resource to download\n",
        "    \"\"\"\n",
        "    temp_file, _ = urllib.request.urlretrieve(url)\n",
        "    with tf.io.gfile.GFile(temp_file, 'r') as temp_file_object:\n",
        "        with tf.io.gfile.GFile(filename, 'w') as file_object:\n",
        "            for line in temp_file_object:\n",
        "                line = line.strip()\n",
        "                line = line.replace(', ', ',')\n",
        "                if not line or ',' not in line:\n",
        "                    continue\n",
        "                if line[-1] == '.':\n",
        "                    line = line[:-1]\n",
        "                line += '\\n'\n",
        "                file_object.write(line)\n",
        "    tf.io.gfile.remove(temp_file)\n",
        "\n",
        "\n",
        "def download(data_dir):\n",
        "    \"\"\"Downloads census data if it is not already present.\n",
        "  \n",
        "    Args:\n",
        "      data_dir: directory where we will access/save the census data\n",
        "    \"\"\"\n",
        "    tf.io.gfile.makedirs(data_dir)\n",
        "\n",
        "    training_file_path = os.path.join(data_dir, TRAINING_FILE)\n",
        "    if not tf.io.gfile.exists(training_file_path):\n",
        "        _download_and_clean_file(training_file_path, TRAINING_URL)\n",
        "\n",
        "    eval_file_path = os.path.join(data_dir, EVAL_FILE)\n",
        "    if not tf.io.gfile.exists(eval_file_path):\n",
        "        _download_and_clean_file(eval_file_path, EVAL_URL)\n",
        "\n",
        "    return training_file_path, eval_file_path"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fuX5SyAOgYsG"
      },
      "source": [
        "Use those functions to download the data for training and verify that you have CSV files for training and evaluation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9Wii7NAss92J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db74ed7a-0079-4528-b502-37f77283ea55"
      },
      "source": [
        "training_file_path, eval_file_path = download(DATA_DIR)\n",
        "\n",
        "# You should see 2 files: adult.data.csv and adult.test.csv\n",
        "!ls -l $DATA_DIR"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5156\n",
            "-rw-r--r-- 1 root root 3518450 Jun 19 17:38 adult.data.csv\n",
            "-rw-r--r-- 1 root root 1758573 Jun 19 17:38 adult.test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tHSJTrDygqpS"
      },
      "source": [
        "Next, load these files using Pandas and examine the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KHWiAYCew28Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "66a00072-52f8-4dd0-df02-8dce7bba2ed4"
      },
      "source": [
        "# This census data uses the value '?' for fields (column) that are missing data. \n",
        "# We use na_values to find ? and set it to NaN values.\n",
        "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
        "\n",
        "train_df = pd.read_csv(training_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "eval_df = pd.read_csv(eval_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "\n",
        "# Here's what the data looks like before we preprocess the data.\n",
        "train_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  ... hours_per_week  native_country income_bracket\n",
              "0   39         State-gov   77516  ...             40   United-States          <=50K\n",
              "1   50  Self-emp-not-inc   83311  ...             13   United-States          <=50K\n",
              "2   38           Private  215646  ...             40   United-States          <=50K\n",
              "3   53           Private  234721  ...             40   United-States          <=50K\n",
              "4   28           Private  338409  ...             40            Cuba          <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Hhsa1-6qVD0n"
      },
      "source": [
        "#### Preprocess the data\n",
        "\n",
        "The first preprocessing step removes certain features from the data and\n",
        "converts categorical features to numerical values for use with Keras.\n",
        "\n",
        "Learn more about [feature engineering](https://developers.google.com/machine-learning/crash-course/representation/feature-engineering) and [bias in data](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WHbJecf1Bb2r"
      },
      "source": [
        "UNUSED_COLUMNS = ['fnlwgt', 'education', 'gender']\n",
        "\n",
        "\n",
        "def preprocess(dataframe):\n",
        "    \"\"\"Converts categorical features to numeric. Removes unused columns.\n",
        "  \n",
        "    Args:\n",
        "      dataframe: Pandas dataframe with raw data\n",
        "  \n",
        "    Returns:\n",
        "      Dataframe with preprocessed data\n",
        "    \"\"\"\n",
        "    dataframe = dataframe.drop(columns=UNUSED_COLUMNS)\n",
        "\n",
        "    # Convert integer valued (numeric) columns to floating point\n",
        "    numeric_columns = dataframe.select_dtypes(['int64']).columns\n",
        "    dataframe[numeric_columns] = dataframe[numeric_columns].astype('float32')\n",
        "\n",
        "    # Convert categorical columns to numeric\n",
        "    cat_columns = dataframe.select_dtypes(['object']).columns\n",
        "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.astype(\n",
        "        _CATEGORICAL_TYPES[x.name]))\n",
        "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.cat.codes)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "prepped_train_df = preprocess(train_df)\n",
        "prepped_eval_df = preprocess(eval_df)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ce0Ln1P-mpwx"
      },
      "source": [
        "Run the following cell to see how preprocessing changed the data. Notice in particular that `income_bracket`, the label that you're training the model to predict, has changed from `<=50K` and `>50K` to `0` and `1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YbMskdWmTCED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a79b35da-d9db-4629-e855-9f76c866e645"
      },
      "source": [
        "prepped_train_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.0</td>\n",
              "      <td>6</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.0</td>\n",
              "      <td>5</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.0</td>\n",
              "      <td>3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  workclass  ...  native_country  income_bracket\n",
              "0  39.0          6  ...              38               0\n",
              "1  50.0          5  ...              38               0\n",
              "2  38.0          3  ...              38               0\n",
              "3  53.0          3  ...              38               0\n",
              "4  28.0          3  ...               4               0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OCzBX6LuCmTT"
      },
      "source": [
        "Next, separate the data into features (\"x\") and labels (\"y\"), and reshape the label arrays into a format for use with `tf.data.Dataset` later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gPq7WY51GW6M"
      },
      "source": [
        "# Split train and test data with labels.\n",
        "# The pop() method will extract (copy) and remove the label column from the dataframe\n",
        "train_x, train_y = prepped_train_df, prepped_train_df.pop(_LABEL_COLUMN)\n",
        "eval_x, eval_y = prepped_eval_df, prepped_eval_df.pop(_LABEL_COLUMN)\n",
        "\n",
        "# Reshape label columns for use with tf.data.Dataset\n",
        "train_y = np.asarray(train_y).astype('float32').reshape((-1, 1))\n",
        "eval_y = np.asarray(eval_y).astype('float32').reshape((-1, 1))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "A1tDH7_RDAIK"
      },
      "source": [
        "Scaling training data so each numerical feature column has a mean of 0 and a standard deviation of 1 [can improve your model](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data).\n",
        "\n",
        "In a production system, you may want to save the means and standard deviations from your training set and use them to perform an identical transformation on test data at prediction time. For convenience in this exercise, temporarily combine the training and evaluation data to scale all of them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OXAMwr3dCsqd"
      },
      "source": [
        "def standardize(dataframe):\n",
        "    \"\"\"Scales numerical columns using their means and standard deviation to get\n",
        "    z-scores: the mean of each numerical column becomes 0, and the standard\n",
        "    deviation becomes 1. This can help the model converge during training.\n",
        "  \n",
        "    Args:\n",
        "      dataframe: Pandas dataframe\n",
        "  \n",
        "    Returns:\n",
        "      Input dataframe with the numerical columns scaled to z-scores\n",
        "    \"\"\"\n",
        "    dtypes = list(zip(dataframe.dtypes.index, map(str, dataframe.dtypes)))\n",
        "    # Normalize numeric columns.\n",
        "    for column, dtype in dtypes:\n",
        "        if dtype == 'float32':\n",
        "            dataframe[column] -= dataframe[column].mean()\n",
        "            dataframe[column] /= dataframe[column].std()\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "# Join train_x and eval_x to normalize on overall means and standard\n",
        "# deviations. Then separate them again.\n",
        "all_x = pd.concat([train_x, eval_x], keys=['train', 'eval'])\n",
        "all_x = standardize(all_x)\n",
        "train_x, eval_x = all_x.xs('train'), all_x.xs('eval')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aqKZk6NawDe-"
      },
      "source": [
        "Finally, examine some of your fully preprocessed training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6NZqE3Wlg1yg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "bdfd95bb-066b-41f2-a51d-6955c5f5acaf"
      },
      "source": [
        "# Verify dataset features\n",
        "# Note how only the numeric fields (not categorical) have been standardized\n",
        "train_x.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.025996</td>\n",
              "      <td>6</td>\n",
              "      <td>1.136850</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.146949</td>\n",
              "      <td>-0.217119</td>\n",
              "      <td>-0.034043</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.828270</td>\n",
              "      <td>5</td>\n",
              "      <td>1.136850</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144807</td>\n",
              "      <td>-0.217119</td>\n",
              "      <td>-2.213206</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.046938</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.419365</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144807</td>\n",
              "      <td>-0.217119</td>\n",
              "      <td>-0.034043</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.047072</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.197472</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144807</td>\n",
              "      <td>-0.217119</td>\n",
              "      <td>-0.034043</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.776277</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136850</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144807</td>\n",
              "      <td>-0.217119</td>\n",
              "      <td>-0.034043</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  workclass  ...  hours_per_week  native_country\n",
              "0  0.025996          6  ...       -0.034043              38\n",
              "1  0.828270          5  ...       -2.213206              38\n",
              "2 -0.046938          3  ...       -0.034043              38\n",
              "3  1.047072          3  ...       -0.034043              38\n",
              "4 -0.776277          3  ...       -0.034043               4\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "V1bLJFrNxHXV"
      },
      "source": [
        "### Design and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iWkmN8ZmwSXU"
      },
      "source": [
        "#### Create training and validation datasets\n",
        "\n",
        "Create an input function to convert features and labels into a\n",
        "[`tf.data.Dataset`](https://www.tensorflow.org/guide/datasets) for training or evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PIfE-YaXwRaU"
      },
      "source": [
        "def input_fn(features, labels, shuffle, num_epochs, batch_size):\n",
        "    \"\"\"Generates an input function to be used for model training.\n",
        "  \n",
        "    Args:\n",
        "      features: numpy array of features used for training or inference\n",
        "      labels: numpy array of labels for each example\n",
        "      shuffle: boolean for whether to shuffle the data or not (set True for\n",
        "        training, False for evaluation)\n",
        "      num_epochs: number of epochs to provide the data for\n",
        "      batch_size: batch size for training\n",
        "  \n",
        "    Returns:\n",
        "      A tf.data.Dataset that can provide data to the Keras model for training or\n",
        "        evaluation\n",
        "    \"\"\"\n",
        "    if labels is None:\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "\n",
        "    # We call repeat after shuffling, rather than before, to prevent separate\n",
        "    # epochs from blending together.\n",
        "    dataset = dataset.repeat(num_epochs)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "f8paLJ_rF84R"
      },
      "source": [
        "Next, create these training and evaluation datasets.Use the `NUM_EPOCHS`\n",
        "and `BATCH_SIZE` hyperparameters defined previously to define how the training\n",
        "dataset provides examples to the model during training. Set up the validation\n",
        "dataset to provide all its examples in one batch, for a single validation step\n",
        "at the end of each training epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_xdC2P5EF7rH"
      },
      "source": [
        "# Pass a numpy array by using DataFrame.values\n",
        "training_dataset = input_fn(features=train_x.values, \n",
        "                    labels=train_y, \n",
        "                    shuffle=True, \n",
        "                    num_epochs=NUM_EPOCHS, \n",
        "                    batch_size=BATCH_SIZE)\n",
        "\n",
        "num_eval_examples = eval_x.shape[0]\n",
        "\n",
        "# Pass a numpy array by using DataFrame.values\n",
        "validation_dataset = input_fn(features=eval_x.values, \n",
        "                    labels=eval_y, \n",
        "                    shuffle=False, \n",
        "                    num_epochs=NUM_EPOCHS, \n",
        "                    batch_size=num_eval_examples)                "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vZrDBXnxggOH"
      },
      "source": [
        "# Design a Keras Model from Scratch. Enter code here.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JY_A0yPyqU08"
      },
      "source": [
        "Design your neural network using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model).\n",
        "\n",
        "This deep neural network (DNN) has several hidden layers, and the last layer uses a sigmoid activation function to output a value between 0 and 1:\n",
        "\n",
        "* The input layer has 100 units using the ReLU activation function.\n",
        "* The hidden layer has 75 units using the ReLU activation function.\n",
        "* The hidden layer has 50 units using the ReLU activation function.\n",
        "* The hidden layer has 25 units using the ReLU activation function.\n",
        "* The output layer has 1 units using a sigmoid activation function.\n",
        "* The optimizer uses the binary cross-entropy loss function, which is appropriate for a binary classification problem like this one.\n",
        "\n",
        "Feel free to change these layers to try to improve the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "j_lsOhQAvzS-"
      },
      "source": [
        "def create_keras_model(input_dim, learning_rate):\n",
        "    \"\"\"Creates Keras Model for Binary Classification.\n",
        "  \n",
        "    Args:\n",
        "      input_dim: How many features the input has\n",
        "      learning_rate: Learning rate for training\n",
        "  \n",
        "    Returns:\n",
        "      The compiled Keras model (still needs to be trained)\n",
        "    \"\"\"\n",
        "    Dense = tf.keras.layers.Dense\n",
        "    #################START CODE HERE##############################################\n",
        "    # Define Keras sequential model with only 5 Dense layers with 100, 75, 50, 25 and 1 neurons each. \n",
        "    #All layers except last one has relu activation. \n",
        "    #Last layer has sigmoid activation.\n",
        "    model = tf.keras.Sequential(\n",
        "      [\n",
        "          Dense(100, activation=tf.nn.relu, kernel_initializer='uniform',\n",
        "                  input_shape=(input_dim,)),\n",
        "          Dense(75, activation=tf.nn.relu, kernel_initializer='uniform'),\n",
        "          Dense(50, activation=tf.nn.relu, kernel_initializer='uniform'),\n",
        "          Dense(25, activation=tf.nn.relu, kernel_initializer='uniform'),\n",
        "          Dense(1, activation=tf.nn.sigmoid, kernel_initializer='uniform')\n",
        "          #Enter more lines here###############################\n",
        "      ])\n",
        "    '''\n",
        "    The input layer has 100 units using the ReLU activation function.\n",
        "    The hidden layer has 75 units using the ReLU activation function.\n",
        "    The hidden layer has 50 units using the ReLU activation function.\n",
        "    The hidden layer has 25 units using the ReLU activation function.\n",
        "    The output layer has 1 units using a sigmoid activation function.\n",
        "    The optimizer uses the binary cross-entropy loss function, which is appropriate for a binary classification problem like this one.\n",
        "    '''\n",
        "    # Custom Optimizer:\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
        "    optimizer = tf.keras.optimizers.RMSprop(\n",
        "        lr=learning_rate)\n",
        "\n",
        "    # Compile Keras model\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mo5zTRNvBWv4"
      },
      "source": [
        "Next, create the Keras model object and examine its structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zdyOuwQcSjaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51cf8dc-2bca-4efc-ba78-01d5f605bd6f"
      },
      "source": [
        "num_train_examples, input_dim = train_x.shape\n",
        "print('Number of features: {}'.format(input_dim))\n",
        "print('Number of examples: {}'.format(num_train_examples))\n",
        "\n",
        "keras_model = create_keras_model(\n",
        "    input_dim=input_dim,\n",
        "    learning_rate=LEARNING_RATE)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 11\n",
            "Number of examples: 32561\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z09AeNjObee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a318b0-2b38-4a23-baf8-8e2a8753a30b"
      },
      "source": [
        "##START CODE HERE#############\n",
        "#Summarize the Model above##########\n",
        "keras_model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               1200      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 75)                7575      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                3800      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 26        \n",
            "=================================================================\n",
            "Total params: 13,876\n",
            "Trainable params: 13,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4cqeQttaHbZt"
      },
      "source": [
        "#### Train and evaluate the model\n",
        "\n",
        "Define a learning rate decay to encourage model paramaters to make smaller\n",
        "changes as training goes on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7eLa_Yoj2rhv"
      },
      "source": [
        "# Setup Learning Rate decay.\n",
        "lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE + 0.02 * (0.5 ** (1 + epoch)),\n",
        "    verbose=True)\n",
        "\n",
        "# Setup TensorBoard callback.\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
        "      os.path.join(JOB_DIR, 'keras_tensorboard'),\n",
        "      histogram_freq=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1fExnH6bhOSC"
      },
      "source": [
        "Finally, train the model. Provide the appropriate `steps_per_epoch` for the\n",
        "model to train on the entire training dataset (with `BATCH_SIZE` examples per step) during each epoch. And instruct the model to calculate validation\n",
        "accuracy with one big validation batch at the end of each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MG4EvLiorMmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df46199-d6a1-4f0f-ef1c-8c73d18d5c7e"
      },
      "source": [
        "keras_history = keras_model.fit(training_dataset, \n",
        "                          epochs=NUM_EPOCHS, \n",
        "                          steps_per_epoch=int(num_train_examples/BATCH_SIZE), \n",
        "                          validation_data=validation_dataset, \n",
        "                          validation_steps=1, \n",
        "                          callbacks=[lr_decay_cb, tensorboard_cb],\n",
        "                          verbose=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 254 steps, validate on 1 steps\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
            "Epoch 1/20\n",
            "254/254 [==============================] - 1s 6ms/step - loss: 0.3408 - acc: 0.8457 - val_loss: 0.3818 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
            "Epoch 2/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3293 - acc: 0.8471 - val_loss: 0.3549 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
            "Epoch 3/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3271 - acc: 0.8480 - val_loss: 0.3215 - val_acc: 0.8524\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
            "Epoch 4/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3224 - acc: 0.8510 - val_loss: 0.3445 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
            "Epoch 5/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3241 - acc: 0.8485 - val_loss: 0.3302 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
            "Epoch 6/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3217 - acc: 0.8507 - val_loss: 0.3746 - val_acc: 0.8473\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
            "Epoch 7/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3212 - acc: 0.8509 - val_loss: 0.3566 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
            "Epoch 8/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3214 - acc: 0.8506 - val_loss: 0.3264 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
            "Epoch 9/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3219 - acc: 0.8508 - val_loss: 0.3246 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
            "Epoch 10/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3199 - acc: 0.8521 - val_loss: 0.3277 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
            "Epoch 11/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3220 - acc: 0.8515 - val_loss: 0.3354 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.010004882812500001.\n",
            "Epoch 12/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3278 - acc: 0.8531 - val_loss: 0.3278 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.\n",
            "Epoch 13/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3238 - acc: 0.8505 - val_loss: 0.3360 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.\n",
            "Epoch 14/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3233 - acc: 0.8524 - val_loss: 0.3328 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.\n",
            "Epoch 15/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3216 - acc: 0.8511 - val_loss: 0.3301 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.01000030517578125.\n",
            "Epoch 16/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3232 - acc: 0.8509 - val_loss: 0.3262 - val_acc: 0.8523\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.010000152587890625.\n",
            "Epoch 17/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3217 - acc: 0.8526 - val_loss: 0.3847 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.010000076293945313.\n",
            "Epoch 18/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3242 - acc: 0.8496 - val_loss: 0.3201 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.010000038146972657.\n",
            "Epoch 19/20\n",
            "254/254 [==============================] - 2s 7ms/step - loss: 0.3218 - acc: 0.8514 - val_loss: 0.3449 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.010000019073486329.\n",
            "Epoch 20/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 0.3293 - acc: 0.8502 - val_loss: 0.3445 - val_acc: 0.8426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fW7vTPm2pd2l"
      },
      "source": [
        "### Visualize training and export the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "S9ZQcgetLHz9"
      },
      "source": [
        "#### Visualize training\n",
        "\n",
        "Import `matplotlib` to visualize how the model learned over the training period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ISzcM0lxMOPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c253e3f5-a155-499d-85e7-fd53e7c163b0"
      },
      "source": [
        "! pip install matplotlib\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "e6tLXXT0SR-q"
      },
      "source": [
        "Plot the model's loss (binary cross-entropy) and accuracy, as measured at the\n",
        "end of each training epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB9i35zEkPK9",
        "outputId": "716736c0-1f4d-4d2a-9390-13ef52a5a0e9"
      },
      "source": [
        "keras_history.history"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.84574926,\n",
              "  0.8471026,\n",
              "  0.8480253,\n",
              "  0.8509781,\n",
              "  0.84845597,\n",
              "  0.8506705,\n",
              "  0.85091656,\n",
              "  0.85057825,\n",
              "  0.85079354,\n",
              "  0.8521469,\n",
              "  0.851501,\n",
              "  0.8531312,\n",
              "  0.85051674,\n",
              "  0.8523622,\n",
              "  0.85110116,\n",
              "  0.85085505,\n",
              "  0.852639,\n",
              "  0.84956324,\n",
              "  0.8514395,\n",
              "  0.8501784],\n",
              " 'loss': [0.3408179873321939,\n",
              "  0.3293035961394235,\n",
              "  0.32707201613215947,\n",
              "  0.3224211414967935,\n",
              "  0.32413134260440435,\n",
              "  0.3216812253937008,\n",
              "  0.32119513754769574,\n",
              "  0.3213865938853091,\n",
              "  0.3219127302446703,\n",
              "  0.31991982342689995,\n",
              "  0.3220169894455925,\n",
              "  0.3277574870882072,\n",
              "  0.32382303916328536,\n",
              "  0.32326540949307087,\n",
              "  0.32157309494149966,\n",
              "  0.3231932001085732,\n",
              "  0.32167416931254655,\n",
              "  0.3241682620499078,\n",
              "  0.3217523243483596,\n",
              "  0.3292522138263297],\n",
              " 'lr': [0.02,\n",
              "  0.015,\n",
              "  0.0125,\n",
              "  0.01125,\n",
              "  0.010625,\n",
              "  0.0103125,\n",
              "  0.01015625,\n",
              "  0.010078125,\n",
              "  0.010039062,\n",
              "  0.0100195315,\n",
              "  0.010009766,\n",
              "  0.010004883,\n",
              "  0.010002442,\n",
              "  0.010001221,\n",
              "  0.010000611,\n",
              "  0.010000305,\n",
              "  0.0100001525,\n",
              "  0.010000076,\n",
              "  0.010000038,\n",
              "  0.010000019],\n",
              " 'val_acc': [0.814965,\n",
              "  0.84998155,\n",
              "  0.8523774,\n",
              "  0.84973586,\n",
              "  0.8504116,\n",
              "  0.84727854,\n",
              "  0.8335176,\n",
              "  0.8491215,\n",
              "  0.85280746,\n",
              "  0.84777,\n",
              "  0.8529303,\n",
              "  0.8529303,\n",
              "  0.8513331,\n",
              "  0.8515174,\n",
              "  0.84869146,\n",
              "  0.852316,\n",
              "  0.8529303,\n",
              "  0.85354465,\n",
              "  0.8517017,\n",
              "  0.84260964],\n",
              " 'val_loss': [0.38184216618537903,\n",
              "  0.3548985719680786,\n",
              "  0.32150623202323914,\n",
              "  0.34447693824768066,\n",
              "  0.3301825225353241,\n",
              "  0.3746383488178253,\n",
              "  0.3566233515739441,\n",
              "  0.3264332413673401,\n",
              "  0.3245576322078705,\n",
              "  0.3277179002761841,\n",
              "  0.3353882133960724,\n",
              "  0.3277750015258789,\n",
              "  0.33603429794311523,\n",
              "  0.3327837288379669,\n",
              "  0.33008190989494324,\n",
              "  0.3261847496032715,\n",
              "  0.3847326934337616,\n",
              "  0.320109486579895,\n",
              "  0.34485211968421936,\n",
              "  0.34446990489959717]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yU1TzdlY0i-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "3b5faf3d-7211-4a46-edf7-f306cbdadb04"
      },
      "source": [
        "# Visualize History for Loss.\n",
        "plt.title('Keras model loss')\n",
        "plt.plot(keras_history.history['loss'])\n",
        "plt.plot(keras_history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Visualize History for Accuracy.\n",
        "plt.title('Keras model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(keras_history.history['acc'])\n",
        "plt.plot(keras_history.history['val_acc'])\n",
        "plt.legend(['training', 'validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1bmH30/dai7q7k2yJdmWu2kGG4MxvYMpCZAQeoALJEBCaEluCOESbi4GQg2hOcaEkmBqKMbgbtx7w5JsS3JR79K5f5wdeS2vpG2zu5LO+zx+Znd25szRWprfnK+KUgqDwWAwGFoTFuwJGAwGgyE0MQJhMBgMBpcYgTAYDAaDS4xAGAwGg8ElRiAMBoPB4BIjEAaDwWBwiREIgyGEEJFrRWSRm8f+TUR+5+s4BkNbGIEwhDQisltETnN6P1tEDovIKcGcl8HQHTACYeg0iMg1wBzgbKXU1x6eG2HPrAyGrosRCEOnQERuBP4HOEMp9Z1jX08ReUlE9olIoYj8TkTCHZ9dKyLfisifReQg8LCIDBORL0TkoIgcEJE3RKSX0zXudYxTISJbRGRGG3P5m4g8IyIfiUil4zrpIvKUY3WzWUTGOR2fLSJfiUipiGwQkfOcPksSkQ9EpFxElgHDWl1rpIh8JiKHHHO6zMvv7wQRWS4iZY7tCU6fXSsiOx0/9y4Rucqxf7iIfO0454CI/MObaxs6L0YgDJ2Bm4FHgRlKqRVO+/8GNALDgXHATOB6p8+nADuBNOD3gAB/APoC2cAA4GEAERkB3AZMUkolAGcAu9uZ02XAA0AyUAcsBlY53s8HnnSMGwn8C/gUSAV+DrzhuB7oFVEtkAH8xPEPx7lxwGfAm45zZwPPiEhOO/M6BhHpA3wI/AVIcsztQ4c4xTn2n+n4uU8AVjtO/a1j3r2B/sD/eXJdQ+fHCIShM3A6sARYZ+0QkTTgLOBOpVSVUqoY+DP6JmqxVyn1f0qpRqVUjVJqu1LqM6VUnVKqBH2jtHwZTUA0kCMikUqp3UqpHe3M6V2l1EqlVC3wLlCrlPq7UqoJ+AdasACOA+KBx5RS9UqpL4B/A1c4VjsXAw86fob1wKtO1zgH2K2UesXxM3wPvANc6uH3dzawTSn1mmOct4DNwLmOz5uBUSLSQym1Tym1wbG/ARgE9FVK1SqljNO7m2EEwtAZuBnIAl4UEXHsGwREAvscpptS4K/oJ22LfOdBRCRNROY6zEjlwOvoJ36UUtuBO9ErimLHcX3bmVOR0+saF+/jHa/7AvlKqWanz38A+gEpQESref7g9HoQMMX6+Rw/41VAejvzckXfVuO2zEEpVQVcDtyE/i4/FJGRjmN+iV51LXOYxn6CoVthBMLQGSgCZgBTgWcc+/LRpp1kpVQvx79EpVSu03mtSxX/t2PfaKVUInA1+gaoD1bqTaXUSegbswL+6Ie57wUGiIjz39pAoBAoQZvIBrT6zCIf+Nrp5+ullIpXSt3sxRwGtdpnzQGl1CdKqdPRZq7NwAuO/fuVUj9TSvUFbkSbt4Z7eG1DJ8YIhKFToJTaixaJWSLyZ6XUPrR9/H9EJFFEwhxO6PbCXxOASqBMRPoBv7A+EJERInKqiESjfQI1aNOLrywFqoFfikikiExDm3bmOsxR/0Q70GMdvoVrnM79N5AlIj9ynBspIpNEJNvDOSxwjHOliESIyOVADvBvx6rqfIcvog79/TQDiMilItLfMcZhtGj64zsxdBKMQBg6DUqpPcCpwCUi8gfgx0AUsBF9A5uPfgpui0eA8UAZ2mn7T6fPooHHgAPAfrSp6n4/zLkeLQhnOsZ+BvixUmqz45Db0Oao/Win+ytO51agHe+z0auA/ehVTbSHcziI9mfcDRxEm47OUUodQN8D7nKMfwjtk7FWKJOApSJSCXwA3KGU2unJtQ2dGzENgwwGg8HgCrOCMBgMBoNLjEAYDAaDwSVGIAwGg8HgEiMQBoPBYHBJlylglpycrAYPHhzsaRgMBkOnYuXKlQeUUimuPusyAjF48GBWrFjR8YEGg8FgaEFEWmfZt2BMTAaDwWBwiREIg8FgMLjECITBYDAYXNJlfBAGg6Fr0dDQQEFBAbW1tcGeSpcgJiaG/v37ExkZ6fY5RiAMBkNIUlBQQEJCAoMHD+ZIlXeDNyilOHjwIAUFBQwZMsTt84yJyWAwhCS1tbUkJSUZcfADIkJSUpLHqzEjEAaDIWQx4uA/vPkujUAYDIbuTW05NBo/hyuMQBgMhu7N4d1QWXTM7tLSUp555pljj++As846i9LS0naPefDBB/n88889HjvQGIEwGAzdF9UMqgmaGo/5qC2BaGw89lhnFixYQK9evdo95tFHH+W0007zbK5BwAiEwWDovljC0HzsTf++++5jx44djB07lkmTJjF16lTOO+88cnJyALjggguYMGECubm5PP/88y3nDR48mAMHDrB7926ys7P52c9+Rm5uLjNnzqSmpgaAa6+9lvnz57cc/9BDDzF+/HhGjx7N5s262WBJSQmnn346ubm5XH/99QwaNIgDBw7Y+W0cgwlzNRgMIc8j/9rAxr3lfh0zp28iD53hCPl0IRCPPfYY69evZ/Xq1Xz11VecffbZrF+/viVM9OWXX6ZPnz7U1NQwadIkLr74YpKSko4aY9u2bbz11lu88MILXHbZZbzzzjtcffXVx1wrOTmZVatW8cwzz/DEE0/w4osv8sgjj3Dqqady//338/HHH/PSSy/59ed3B7OCMBgM3ZfmBse2fbMRwOTJk4/KIfjLX/5CXl4exx13HPn5+Wzbtu2Yc4YMGcLYsWMBmDBhArt373Y59kUXXXTMMYsWLWL27NkAzJo1i969e7v7U/kNs4IwGAwhz0Pn5tozcPVBvVXN0NwMYW0/M8fFxbW8/uqrr/j8889ZvHgxsbGxTJs2zWWOQXR0dMvr8PDwFhNTW8eFh4d36OMIJGYFYTAYui9NDUdet1pFJCQkUFFR4fK0srIyevfuTWxsLJs3b2bJkiV+n9qJJ57IvHnzAPj00085fPiw36/REWYFYTAYui/OotDcCES1vE1KSuLEE09k1KhR9OjRg7S0tJbPZs2axXPPPUd2djYjRozguOOO8/vUHnroIa644gpee+01jj/+eNLT00lISPD7ddpDlFIBvaBdTJw4UXnVMKh4M3z+EMx4ENJsWsYaDAaP2bRpE9nZ2fZe5NBuqHU8mfcZBjGJ9l7PA+rq6ggPDyciIoLFixdz8803s3r1ap/GdPWdishKpdREV8ebFUREFGz9GEacZQTCYOhuNDeAhOtcCDcc1YFkz549XHbZZTQ3NxMVFcULL7wQ8DkYgeg9BKJ7wr41wZ6JwWAINM2NENkD6itDTiAyMzP5/vvvgzoH46QWgYwxRiAMhu5IcyNERB95bTgKWwVCRGaJyBYR2S4i97n4/CYRWSciq0VkkYjkOPZHisirjs82icj9ds6TjDwoWu8y3d5gMHRRlNKiEBYJYRFGIFxgm0CISDgwBzgTyAGusATAiTeVUqOVUmOBx4EnHfsvBaKVUqOBCcCNIjLYrrmSkaerOR7YatslDAZDiGEJQniEEYg2sHMFMRnYrpTaqZSqB+YC5zsfoJRyzp2PA6yQKgXEiUgE0AOoB/ybZ+9M+hi9NWYmg6H7YOVAmBVEm9gpEP2AfKf3BY59RyEit4rIDvQK4nbH7vlAFbAP2AM8oZQ65OLcG0RkhYisKCkp8X6myZkQ0cMIhMHQnbAEIcyxgvDRxBwfHw/A3r17ueSSS1weM23aNDoKx3/qqaeorq5uee9O+XC7CLqTWik1Ryk1DLgXeMCxezLQBPQFhgB3i8hQF+c+r5SaqJSamJKS4v0kwsIhfbQRCIOhO2HVYfKzialv374tlVq9obVAuFM+3C7sFIhCYIDT+/6OfW0xF7jA8fpK4GOlVINSqhj4FnCZyOE3MvJg/1pdj8VgMHR9WlYQDhOTatKOawf33Xcfc+bMaXn/8MMP87vf/Y4ZM2a0lOZ+//33jxl29+7djBo1CoCamhpmz55NdnY2F1544VG1mG6++WYmTpxIbm4uDz30EKALAO7du5fp06czffp04Ej5cIAnn3ySUaNGMWrUKJ566qmW67VVVtxX7MyDWA5kisgQtDDMRt/4WxCRTKWUVQLxbMB6vQc4FXhNROKA44CnbJyrFojlL8ChnZA83NZLGQwGD/noPti/zr9j9hkCk64HCdMCAVo0wiMBuPzyy7nzzju59dZbAZg3bx6ffPIJt99+O4mJiRw4cIDjjjuO8847r81+z88++yyxsbFs2rSJtWvXMn78+JbPfv/739OnTx+ampqYMWMGa9eu5fbbb+fJJ5/kyy+/JDk5+aixVq5cySuvvMLSpUtRSjFlyhROOeUUevfu7XZZcU+xbQWhlGoEbgM+ATYB85RSG0TkURE5z3HYbSKyQURWA3cB1zj2zwHiRWQDWmheUUqttWuugBYIgP3GzGQwdAtUsxYDEW1mgqPMTOPGjaO4uJi9e/eyZs0aevfuTXp6Or/61a8YM2YMp512GoWFhRQVHduu1GLhwoUtN+oxY8YwZsyYls/mzZvH+PHjGTduHBs2bGDjxo3tTnfRokVceOGFxMXFER8fz0UXXcQ333wDuF9W3FNszaRWSi0AFrTa96DT6zvaOK8SHeoaOFJGQniU9kOMujiglzYYDB1w5mP+H/PAdm1WgqNXEE5ceumlzJ8/n/3793P55ZfzxhtvUFJSwsqVK4mMjGTw4MEuy3x3xK5du3jiiSdYvnw5vXv35tprr/VqHAt3y4p7StCd1CFDRBSk5hhHtcHQXWhuPCIMbQjE5Zdfzty5c5k/fz6XXnopZWVlpKamEhkZyZdffskPP/zQ7iVOPvlk3nzzTQDWr1/P2rXaEFJeXk5cXBw9e/akqKiIjz76qOWctsqMT506lffee4/q6mqqqqp49913mTp1qrc/vVuYWkzOZOTBpg+0o6oNm6LBYOgiNDdAVKx+3YZA5ObmUlFRQb9+/cjIyOCqq67i3HPPZfTo0UycOJGRI0e2e4mbb76Z6667juzsbLKzs5kwYQIAeXl5jBs3jpEjRzJgwABOPPHElnNuuOEGZs2aRd++ffnyyy9b9o8fP55rr72WyZMnA3D99dczbtw4v5mTXGHKfTuz/CX48C64cx30GuifiRkMBq+wtdy3UrBvNcSnQWJf7Y/YtwYS0iEhw55rhgCelvs2JiZnMrSTx5iZDIYujnOIK+hIJgk32dStMALhTFqO/iUxAmEwdG2c6zBZ+CGbuqthBMKZyB6QMsIIhMEQIthmAncus2HRxesxefNdGoFoTUaeEQiDIQSIiYnh4MGD9oiEc6E+i7AIaG7y/7VCAKUUBw8eJCYmxqPzTBRTazLyYM1bULFfO6wMBkNQ6N+/PwUFBfhUiLMt6iqg5jCURmn/A0D1IWisgYNdI3CnNTExMfTv39+jc4xAtMbKqN631giEwRBEIiMjGTJkiD2Df/YQLHkGHig+EtL++cPw3dPwmxIT5u7AmJhakz5ab42ZyT2aGuHfd8HBHcGeicHgPlUlEJdytBDEJunciNqy4M0rxDAC0ZroBEgarmOkDR1zYAuseAmWvxjsmRgM7lNZrAXCmVhHcbzqg4GfT4hiBMIVGXnaxGTomLICvd32aXDnYTB4QlUxxKcevS/OCERrjEC4IiMPyvZop5WhfcocTQMPbjdmJkPnobIE4loJRGyS3lYdCPx8QhQjEK5ocVQbP0SHlBUADjvuts+COhWDwS2U0j6I+FYmppYVhBEICyMQrkh31Gw3AtExpfnQexAkZcK2T4I9G4OhY2oOa2d0Wz4Is4JowQiEK2L7QM+BRiDcoawAeg6AzJmwexHUVQZ7RgZD+1Q58ipam5iiYiGih/FBOGEEoi0yxhiBcAdLILJmQlM97FoY7BkZDO1TWay3rU1MoM1MRiBaMALRFhlj4dAOqC0P9kxCl6ZGqNgLPfvDwBMgKt6YmQyhT5VDIFqvIEA7qo2JqQUjEG1hOaqL1gd3HqFMxV5dR79nf92Rb+g07ajuIj1GDF2USoeJqXWYKzhWEEYgLIxAtIWJZOoYKweip6O+S9YZUF4IRRuCNyeDoSOqinVZ/x59jv0sNhmqjInJwghEWySkQXy6EYj2sATC6r43/HS9NWYmQyhTWaxXCmEubn+xScYH4YStAiEis0Rki4hsF5H7XHx+k4isE5HVIrJIRHIc+69y7LP+NYvIWDvn6hJT+rt9rCS5xH6ObYYOEd5qsqoNIUyViyQ5i7gkaKiChprAzilEsU0gRCQcmAOcCeQAV1gC4MSbSqnRSqmxwOPAkwBKqTeUUmMd+38E7FJKBb44UkYelGyG+uqAX7pTUFagn7isxu+gzUwFy0wWuiF0qSx2HcEEJheiFXauICYD25VSO5VS9cBc4HznA5RSziFCcYAr7+YVjnMDT0aedsIWbwzK5UOe0vwj/geLzDP0d7bji+DMyWDoiHZXECab2hk7BaIfkO/0vsCx7yhE5FYR2YFeQdzuYpzLgbdcXUBEbhCRFSKywpamIi2OalPZ1SVWDoQz/cbrVYUp3mcIRZRycwVh/BAQAk5qpdQcpdQw4F7gAefPRGQKUK2UchlrqpR6Xik1USk1MSWljf9wX+jZH3r0Nn4IVyilfRCtBSIsHIafpsNdu2j7RkMnpq4cmuraXkFYBfuMoxqwVyAKAee7R3/HvraYC1zQat9s2lg9BAQR46hui9oyqK881sQEuuxGzSEoXBn4eRkM7dFeDgRoJzUYE5MDOwViOZApIkNEJAp9s//A+QARyXR6ezawzemzMOAyguV/sMjIg6KN0Fgf1GmEHFYEkyuBGHaq7vNrzEyGUKMli7oNi0NMLwiLME5qB7YJhFKqEbgN+ATYBMxTSm0QkUdF5DzHYbeJyAYRWQ3cBVzjNMTJQL5Saqddc3SLjDxd+bFkc1CnEXK05EAMOPaz2D4wYApsNfkQhhCjpQ5TGysIEUcuhBEIgAg7B1dKLQAWtNr3oNPrO9o59yvgONsm5y4ZjvSLfWt0AT+DpiWL2oVAgDYz/ecRKN+n8yMMhlCgrUquzphs6haC7qQOeXoPgagE44doTVk+hEcfifpoTeZMvd1umggZQojKYkCOOKNdEdvHOKkdGIHoiLAwU/rbFaX50LOf63IFAGm5OsPamJkMoURVsRaH8HaMJ6ZgXwtGINwhIw/2rzNhm864yoFwRgQyT4edX0FjXcCmZTC0S2VJ2/4Hi9hk46R2YATCHTLyoLEGDmzr+NjuQkcCATqrur4S9iwOzJwMho6oKmk7gskiLhlqS6GpITBzCmGMQLiDKf19NE0NULHPdYirM0NPgfAoU7zPEDpUFbuxgrByIUw9MSMQ7pCUqXvVGoHQlBcCqmOBiIqDwSeZfAhD6FDZTh0mi1iTLGdhBMIdwiO009UIhKa9HIjWZJ4BB7fBoeCmsxgM1FfpUt5t1WGyaCnYZyKZjEC4S0Ye7F8Lzc3Bnknw6SgHwplMRxMhY2YyBJvKdnpRO2NKfrdgBMJdMvJ0oa/S3cGeSfBpaRTUt+Njk4ZB0nBjZjIEn6oO6jBZmBVEC0Yg3MU4qo9Qmq8jQSJ7uHd85hmwe5Fe4hsMwaKygzpMFlavarOCMALhNqnZEBZpBAIcIa4dOKidyZqpSyzv/Nq+ORkMHVHVQR0mi/AIXbTPOKmNQLhNRLQWCSMQ7uVAODPwBIiKN2YmQ3CxSn13tIIARza1MTEZgfAEqzeEctUZtZuglOcCEREFQ6dpgejO350huFQV6wZg4ZEdH2uyqQEjEJ6RkaefKsrb63vUxak5rEMFPTExAWSdob+3og32zMtg6IjKYvdWD2BWEA6MQHiCc+nv7kp7jYLaY7gj3NWYmQzBosqNJDmL2CSzgsAIhGek5epOad1aIDxIknMmMQPSxxiBMASPyuKOk+QsrBVEN897MgLhCVGxkDzCCAR45oOwyJwJ+UtNjRtDcPB0BaGaoK7M3jmFOEYgPKW794Yo3QMRMe03XGmLrDNANcOOL/w/L4OhPRpqdaKruyuIlmzq7u2HMALhKRl5upKplXTT3bByIEQ8P7ffBJ2EZMxMhkBT5WaZDYs4U7APjEB4TktG9drgziNYeBri6kxYOAw/DbZ/bpovGQJLpZtlNixMPSbACITnpI/W232rgzuPYOFpFnVrss7Qzr/CVf6bk8HQER6vIKx6TEYgDJ4Q0xP6DO2efojGOqjc7/0KAmDYqToSbJvpVW0IIJZJ2G0fhGViMj4I2xCRWSKyRUS2i8h9Lj6/SUTWichqEVkkIjlOn40RkcUissFxTIydc/UIK6O6u2ElCPqygojtA/0nGz+EIbB4uoKI7AGRccZJbdfAIhIOzAHOBHKAK5wFwMGbSqnRSqmxwOPAk45zI4DXgZuUUrnANCB0GsRm5EHpDzqruDvhbQ5Ea7JmaoGt2O/7nAwGd6gsgehEiPTgOTMuyZiYbBx7MrBdKbVTKVUPzAXOdz5AKVXu9DYOsAr1zATWKqXWOI47qJQKHa9md3VUt+RA+LCCAF3+G8wqwhA4qjwos2Fh6jHZKhD9gHyn9wWOfUchIreKyA70CuJ2x+4sQInIJyKySkR+6eoCInKDiKwQkRUlJSV+nn47pHfT3hClVqOgY/4bPSMtV49hBMIQKCpL3I9gsohLNiuIYE9AKTVHKTUMuBd4wLE7AjgJuMqxvVBEZrg493ml1ESl1MSUFA+fDnwhLkk7arubQJTlQ3yaLn3uCyK6FemOr6Cx3i9TMxjaxasVRFK3z/q3UyAKAWdjdX/HvraYC1zgeF0ALFRKHVBKVQMLgPG2zNJb0rthRrUvORCtyTwD6itgz3f+Gc9gaI/KYs9XEKZgn60CsRzIFJEhIhIFzAY+cD5ARDKd3p4NbHO8/gQYLSKxDof1KcBGG+fqORl5cHA71FUGeyaBw9ccCGeGnAzhUbDtM/+MZzC0RWM91Ja6H8FkEZcMjTXdulWubQKhlGoEbkPf7DcB85RSG0TkURE5z3HYbY4w1tXAXcA1jnMPoyOalgOrgVVKqQ/tmqtXZOQBCorWB3smgaGlUZCfBCI6HgafBFtNPoTBZqqsLGovnNTQrVcREXYOrpRagDYPOe970On1He2c+zo61DU0yXByVA88LrhzCQTVB/XTlL9MTKCru358HxzaqZMPDQY78DQHwsI5m7r3IP/OqZMQdCd1pyUhXf/CdRc/hNUoyNccCGcyZ+qtMTMZ7MRaAXjjg4Bu7ag2AuEtIt0ro9pfORDOJA2DpOHGzGSwF6vMhjdRTNCtTUxGIHwhIw+KN+la810dKwfCnyYm0KuI3Yu6tSPQYDOWicmbPAjo1rkQRiB8ISNPd50q3hDsmdhPWQFExkKP3v4dN3MmNNXBroX+HddgsKgs0XWVouI8Oy86EcIizQrC4CUZ3Sijuixfrx68aRTUHgOPBwmHwpX+HddgsKjyoBe1MyLdPpvaCIQv9BoIMb26iUD4McTVmcgY7Yso3uT/sQ0G0D4ITyOYLLp5NrURCF/oTo7qsnx7BAIgNRuKuoGZzhAcqryow2TRzbOpjUD4SsYYKNoITaFTjdzvNNToPzJ/O6gtUnPh8G7jqDbYQ6UXdZgsjInJ4BMZY7WTtWRLsGdiH+V79dafORDOpGYDCko22zO+ofvS1KiTPL1eQSR366ZBRiB8xepR3ZVLblhJcnaZmNJy9db4IQz+pvogoHxbQdSVdduqw0YgfKXPUAiLgANbgz0T+yi1WSB6D4aIHtpUZzD4kyovk+QsYvvobU33dFS7JRAicoeIJIrmJUcTn5l2T65TEB4JvYd0bYEoKwAEEvraM35YOKSM6B75JIbAUullkpxFNy/Y5+4K4ieO9qAzgd7Aj4DHbJtVZyNlBBzY1vFxnZWyAkjIgIgo+66RmmNMTAb/Y1Vy9TbMtZtnU7srEFZ21FnAa0qpDU77DMmZcHCHdoh1RewMcbVIy4HKom7tEDTYQMsKwlsTk1lBuMNKEfkULRCfiEgC0GzftDoZyVnQ3KBDNbsigRCI1Gy9LTZ+CIMfqSqG8GhdNsMbWlYQ3fPBxV2B+ClwHzDJ0QI0ErjOtll1NpKz9LYr+iGam6GsMAACYUUyGYEw+JFKR5KctyVievQGxAhEBxwPbFFKlYrI1cADQJl90+pkJDs6p3ZFgag+oPM8eg209zoJ6fqP0QiEwZ9U+ZAkBzqAokdvY2LqgGeBahHJA+4GdgB/t21WnY2YnhCf3jUFwu4cCAsR7ag2oa4Gf1LpQ5kNi26cTe2uQDQqpRRwPvC0UmoOkGDftDohyZldUyDszoFwxopkUsr+axm6B76uIKBbZ1O7KxAVInI/Orz1QxEJQ/shDBbJWVogutrNzY5Ocm2Rmg31FUdWLQaDLzQ3a9OQzyuIJLOC6IDLgTp0PsR+oD/wJ9tm1RlJGQG1ZUfC6roKZQUQlaDLmtuNKblh8Cc1h3RDL29zICxik40Poj0covAG0FNEzgFqlVId+iBEZJaIbBGR7SJyn4vPbxKRdSKyWkQWiUiOY/9gEalx7F8tIs95+HMFnq7qqLZCXP3dKMgVKSP11pT+NvgDX3MgLGKTtNg0d7/IfndLbVwGLAMuBS4DlorIJR2cEw7MAc4EcoArLAFw4k2l1Gil1FjgceBJp892KKXGOv7d5N6PE0S6aqhrIHIgLHr0gsT+ZgVh8A8tdZj84KRWzVBb6vucOhkRbh73a3QORDGAiKQAnwPz2zlnMrBdKbXTcc5ctJO7JUzFUb7DIg7ovAb8xH66721XK7lRVgB9xwfueqnZJtTV4B8qHWU2fPVBOGdTW8X7ugnu+iDCLHFwcNCNc/sBzt7GAse+oxCRW0VkB3oFcbvTR0NE5HsR+VpEprq6gIjcICIrRGRFSUmJWz+IbYg4Ipm6UF+I+mqdIGRXHwhXpOXoVVhXbsBkCAy+VnK1iEvS227oqHZXID4WkU9E5FoRuRb4EFjgjwkopeYopYYB96IT8AD2AQOVUuOAu4A3ReSYXHml1PNKqYlKqYkpKT7+EviD5KyutYIoL6As6XIAACAASURBVNRbuzrJuSI1B5rqdW0rg8EXKoshLNKRDe0D3bgek7tO6l8AzwNjHP+eV0rd28FphYDznaW/Y19bzAUucFyvTil10PF6JToxL8uduQaV5Cxts+8qrTNL9+htoHwQoAUCjJnJ4DtVJXr14GuARay1guh+uRBuNwxSSr2jlLrL8e9dN05ZDmSKyBARiQJmAx84HyAimU5vzwa2OfanOJzciMhQIBPY6e5cg0aKQ8MObg/uPPxFIHMgLJKzQMKNQBh8p6rE9wgm6NYlv9t1UotIBa4dxwIopVSbJRKVUo0ichvwCRAOvKyU2iAijwIrlFIfALeJyGlAA3AYuMZx+snAoyLSgK4ae5NSKvRbOlmRTCVbISMvuHPxB2UFIGH2NQpyRWQMJA0zJTcMvlNZ7HsEE0BEtM4F6obZ1O0KhFLKp3IaSqkFtPJVKKUedHp9RxvnvQO848u1g0KfofqG2lVCXcsKtDiEuxvs5idSs2Hf2sBe09D1qCo5knzpK900m9r0pPYnEdG6v3KXEYgA5kA4k5qre2t0FV+OIfAodcQH4Q+6aTa1EQh/k9yF2o8GSyDScgAFJZsDf21D16C2VEfD+ZoDYRGbZJzUBj+QnKmd1M1NwZ6JbwSqUZArrEgm44cweEulj72oWxOXbATC4AeSs3SDndIfgj0T36gq1m1UA5kkZ9F7MET0MCU3DN5T5ac6TBaxSdrE1NWqNXeAEQh/01KTqZObmVr6QARBIMLCdXXcYlO0z+AllX6qw2QRl6wf/Oor/TNeJ8EIhL+xqrqWdPKSG4HqJNcWablmBWHwnio/1WGy6KbZ1EYg/E1sHx050dkjmYKRJOdMajZUFnXL2HODH6gs1gmXPfxUXK8lmzr007H8iREIO+gKNZnKCiC6p+63HQxMyQ2DL1QVa7NQmJ9ucd00m9oIhB10hf7UwQpxtTACYfCFSj/mQMCRFUQ3MzEFOEW2m5A8Qnegqjpw5MmjsxFsgUhI11U4jUAYvKGq2L8CYecK4oOfQ/4y/fveo4/exjq/7nPkM+t1ZA//z8MFRiDswLm7nN0C0VADC+6BqfdAnyH+G7esAPpP9t94niKiVxEmF8LgDZUlkDTcf+NFxUN4tP9XEA018P0b2uoQFqHD4/d+rx8wG2vbPi+ix9HiMexUmHqXf+eGEQh7cO5PPegEe6+1+1v4/nWIjIWz/uSfMesqoeZwcHIgnEnNgTVzdex5IHpiG7oGSvl/BSHiSJbzs5N631pQTTDjQRh59tGfNdTo69Uc1oLh/LrmMFQ7vbYp/NYIhB30HKAVPhCO6vylertuPsz8PURE+T5mSwRTsAUiG+ortLmr18DgzsXQeair0E/f/gpxtYjt438TU+EKve034djPIntAz376X5AwTmo7CAuD5OGByYXIXwIRMfpJYvtn/hkz2CGuFlYlTmNmMnhClZ/LbFjYUbCvcCUk9tc+txDECIRdJGfZH8nU1AgFK2HslXo5veYt/4wb7CQ5i9RsvTWOaoMnVPq5zIZFXLINK4iV0G+8f8f0I0Yg7CI5S7fsbKix7xpF66GhCgadCKMvgy0f+8dGWlagk4wSMnwfyxdieuqnKyMQBk+o8nOZDYvYZP8mblYd0GXt+0/035h+xgiEXSRnAcre9qP5y/R2wBTIm62L6234p+/jluVDYj9dEynYpOWYkhsGz2hZQfhZIOKStE+ssc4/4xWu0ltX/ocQwQiEXTiHutpF/hLd8a1nf0gfrRvtrJnr+7hlBcE3L1mkZmtfTlNDsGdi6CxUlQBypH6Sv2gpt+GnVUThCt2BMmOsf8azASMQdpE0DBB7I5nyl8HAKToET0SvIgqWwwEfVy3BTpJzJjVXr4wO7gj2TAydhcpiHXHk71a5/i7YV7gSUrIhOt4/49mAEQi7iOyhQzPtWkGUFeob+YDjjuwbfal+IvHFWd3cBOV7g58DYdHiqDalvw1uUlXif/8D+DebWqmQd1CDEQh7SRkBJTYJRP4SvR3glO2cmAFDp8Paf+iOcN5QsR+aG0NnBZGcpR3mxg9hcJfKYv9HMIHTCsIPJqZDO3WCWwj7H8AIBPmHqrnn7TWUVPjJ8eRMchYc3Ob9zbo98pfp7On00UfvH3ulXln88K1344ZKkpxFZIw215lcCIO7VBXbvILwg0BYDuoQjmACmwVCRGaJyBYR2S4i97n4/CYRWSciq0VkkYjktPp8oIhUisg9ds2xsVnxzqoCXv1ut/8HT87UGZ1WXoE/2bNEP32ERx69f8RZEJXgvbM6VHIgnEnNMaGuBvepLPF/BBNATC9twvWHialwpa62kJLt+1g2YptAiEg4MAc4E8gBrmgtAMCbSqnRSqmxwOPAk60+fxL4yK45AgxJjmNmThqvLfmB6vpG/w5uV/vR+irYv06Ht7YmKhZyz4eN70F9tedjh0oWtTOpOTpevL4q2DMxhDr1VTo3yJ91mCzCwnRFVX84qQtXQN+x/nek+xk7VxCTge1KqZ1KqXpgLnC+8wFKqXKnt3FAS0dwEbkA2AXY7p284eShlNU0MG+5n5/0k0fo7QE/l9woXKkLfLkSCIC8K3Txrs0fej52Wb5+UopO8G2O/iQtB1BQsjnYMzGEOnblQFj4I5u6sV4X6Qtx/wPYKxD9AOc7boFj31GIyK0isgO9grjdsS8euBd4pL0LiMgNIrJCRFaUlJR4PdEJg/owYVBvXly0i8YmP/oL4pL0E4e/I5msAn0DJrn+fOAJ0HOgd9FMZQWh43+wsJoHGT+EoSOsp3s7fBDgn2zq4g3QVNftBcItlFJzlFLD0ILwgGP3w8CflVLt1rBVSj2vlJqolJqYkuLbkvKGk4dScLiGj9bv92mcY7Cj/eiepZAyUteBd0VYGORdDju/hPJ9no0dSklyFr0Ha3utiWQydESVTXWYLOKSfHdSF7RTwTXEsFMgCgHnR9H+jn1tMRe4wPF6CvC4iOwG7gR+JSK32TFJi9Oz0xiSHMfzC3eilOr4BHdJzvRvVdfmZihY1rZ5yWLMbFDNsO5tz8Yvyw+dHAiLsHBIHWlyIQwdU2lTHSaL2CTfTUyFq7SPpBOUsLdTIJYDmSIyRESigNnAB84HiEim09uzgW0ASqmpSqnBSqnBwFPAfyulnrZxroSFCddPHcK6wjKW7PRjU5CUEfoXyl+NRg5sgdqyjgUieTj0n6TNTO4KXm25HjvUVhDgiGQyKwhDB7SU+rZpBRHraBrU3OT9GIUr9eqhEzTBsk0glFKNwG3AJ8AmYJ5SaoOIPCoi5zkOu01ENojIauAu4Bq75uMOF4/vT1JcFM8v9GNZB39HMln+h4HHtX8c6NIbxRt1xJM7hGIEk0VqDlQW+beapqHrUVmsgyz80TjLFXHJgNJJbt5QW6Z9kv1CO//BwlYfhFJqgVIqSyk1TCn1e8e+B5VSHzhe36GUylVKjVVKTVdKHWNDUEo9rJR6ws55WsREhnPNCYP5cksJW4sq/DOoc/tRf7BnqX6K6TO042NzL4KwSPdzIkItSc4ZU3LD4A5VxfZFMMGRgn3ehrru/R5QIV9iwyLoTupQ40fHDSImMoznF+70z4C9Bulm5/4Kdc1fqs1L7ixPY/vAiFmwbp5uLtQRLUlyISgQVnc5Y2YytEelTXWYLHzNpi5cqbdGIDonveOiuGziAN5fXUhRea3vA4aFQ9Jw/5iYKkvg0A5dwdVd8q7QdtkdX3R8bFm+XnHEp3k/R7uIT9NRW0VmBWFohyqb6jBZtJT89nIFUbBS3w/aikAMMYxAuOD6k4bS1Kx45dvd/hkwOdM/JqaW/AcPBGL46ToXw52ciLICSOyrw2RDDRFd+tusIAztYfcKwpeS30rpDOpOEN5qEYJ3guAzMCmWM0dl8MbSH6is80P5jeQsXSrC105U+UshPMqzBiMRUTD6Ep1VXVPa/rGhmCTnTGq2Fgh/hiEbug4NtVBXFqAVhBcmpvK9OtDCCETn54aTh1JR28jcZXt8HyxlhM5J8LXpTf5SLQ6RMZ6dlzdbZ25ufK/948oKQi8Hwpm0HN3y0Y7ih4bOT0uIq40riIgoiO7p3Qqi0EqQ6xwRTGAEok3yBvRi8pA+vLxoFw2+lt/wRyRTY52OgPDE/2DRd7xexbQXzdTUqJ9wQjHE1cKU3PA/tWXw7Enw9nWeZ92HGlYWtV05EBZxXibLFa7UPr70Uf6fk00YgWiHG08eyt6yWj5c6+MfTtJwvfXFUb13NTTVe+Z/sLDake5ZrBuVuKJiny4AGNICYYW6djGBCKbJ7D+P6tDhzR/C05Ng6V99SwILJpWOFYSdYa7gyKb2wsRUuEr3b4mI9v+cbMIIRDtMH5HK8NR4/upr+Y2oOG3b92UF4Y2D2pnRlwECa+e5/jyUk+QsYnpCYv+uJRAVRfD0RFj8TOCvvWcpLH8JptwEty7RxR8/+iW8cKojXr+TEagVhDcF+5qb9Hca4g2CWmMEoh3CwoQbpg5l075yFm33sf5KcpZvuRD5S6H3EO+fjnoNgCFT2y690SIQIV4fJq0LldxQCv51BxzcDp/9BvatCdy1G+vgX7frB4Lpv9aJl1f/Ey55Wa8mXzgVPrpXl1/pLNhd6tvCGxNTyRZdgr8TOajBCESHnD+uLykJ0b4nzllVXb1pP6qUFgh3ymu0R96VOprKWo0405Ikd0xF9tAiNUf/sTU1BHsmvvP967D1IzjlXv3U+88bdCROIFj0lO6vcfaTEB2v94nAqIvhtuUw6Xptbnp6Emx4t3NEjlWV6G6KkT3svU5ssnZSe/KdtCTIGYHoUkRHhHPtCYP5ZtsBNuwt836g5ExoqIaKvZ6fe2in/uUfMNn76wNkn6v7WLvKiSjL1/kSUXG+XcNuUnOgucH3iLBgc/gH+Ph+GDwVTrkPzn9a37C/+K391y7ZAt88ocUga+axn8f0hLP+BD/7j34af/taeONSOLTL/rn5QqXNSXIWccn6d7DOg9VV4Qr9vfYZZt+8bMAIhBtcPWUQsVHhvPiND38gVtE+b0p/5y/T2wE+riCi4yH7PFj/7rFPqqHYB8IVaY5Ips5ck6m5Gd6/Vb8+f45OTBx+mn5qXzwHdn1j77X/dad+UJj1WPvH9psAP/tSH7dnMTxzHHzzP7ojWihSZXOSnEWsF+U2ClfqaMJQTEJth8412yDRMzaS2ZMG8q81e9lbWuPdIClW+1EvIpnyl+jY65SR3l3bmbzZOploa6tW32UFnaI+PclZIOGd2w+x9DnY/Q3M+gP0HnRk/+mPal/Ae7fYZ/tf9Srs+Q7O+L17tvrwCDjuZm12ypypo57+OhV++M6e+flCoFYQLQX73BSI+modmt3JzEtgBMJtfnLSYBTw8iIvVxFxKXqJ6U0kU/4yHWHij6ePISdDQt9jcyI6ywoiIlqHDXfWXIiSrfCfRyBrFoy7+ujPouLgwr9CeYE2P/mbiv3w2UParDX2Ks/OTewLl78GV87TptJXzoT3bg2t8utVxYFZQcR5WI9p3xodQt7JIpjACITb9O8dy9mjM3hr2R7KarxwkIo4HNUeCkRNqX5a9tW8ZBEWDmMug22fHYkbrynV9tTOIBDgKLnRCQWiqQHevUGbd879i+uKvAMmwdS7YfXrOjfBnyz4BTTWwrn/632zmqwz4JalcNJ/wdq5OkT3+9eD78RuatA9GuyOYALP6zFZDuq+naOCqzNGIDzghpOHUlXfxFvelt/wRiAKlgPKdwe1M3mz9RPN+vn6fWfIgXAmLVdHY9VXBXsmnvHNkzoW/pwnIaGdirkn/xLSx8AHtx8RcV/Z/CFs+gCm3QtJPjpKo2LhtIfhpkXadPr+rfDCdNj2efCEwu5Ocs60lPz2QCB6Dmj//zxEMQLhAaP69eTE4Um88u0u6hu9CFdNztLFujoqmudM/lJtc/en/TI1W9d0sqKZOksOhEVqNqCgeHOwZ+I+e7+HhY/D6Esh98L2j42Igoueh7oKnSfh6023thw+vAfSRsEJt/s2ljOp2XDtArjgOe2wfeNieHmWvU72tghUDgRoU2BED/ed1J2sgqszRiA85IaTh1FUXsf7qws9P9mKZDq43f1z9izRtVusWHV/kXeFto0WbXTKgegkKwirJlNnMTM11MK7N+mn27P+5N45qdkw40HY8iGsfsO36//nUZ38du5fIDzSt7FaExYGY6+A21bqnIrSPfDqOfDquTpTO1AEolCfM7FJ7vlfKkv0d2IEontwcmYyI9MTeOEbL8pvtPSndtPM1NSol6f+8j84M+piCIvQduSyfF1GPBDLc3/Qe7B+gussAvHFb3WOw3lPe9Yo5rhbtEP5o/t03oQ35C+D5S/ClBuhv403qYgomPRTuP17HRZbvAlengmvXxKYsh0tK4gA/Q67m029d5XeGoHoHogIP5s6lK1FlXy1xUP7cO/Bupqju7kQRet0xIg//Q8W8Sm6mdDaefrmk9iv88Roh4VD6sjOIRC7v9W5DRN/ApmneXZuWBhc4KjR9N4tnmfhN9ZrP0ZiPzj1Ac/O9ZbIGB0We8caOO0RbV55fhrMvcreboAtdZgCtYJIds9JXbACJAz6etDDJYToJHeE0OLcvL6kJ8Z4Xn4jPEI7CN3NhbAS5HwtsdEWebO16WHrJ53HvGSRmhP6oa51FfDezTrX4XQvM6R7DYQz/wg/LIIlczw799unoGSTdopHJ3h3fW+JioOT7oQ71sK0X8GuhfDsiTD/J/5pv9uayhIdHeZvU2xbxCW7t4IoXKl/V0O9QkEb2CoQIjJLRLaIyHYRuc/F5zeJyDoRWS0ii0Qkx7F/smPfahFZIyIdePUCS1REGD85aTCLdx5kXYGH5Tc8aT+6Z4l++rPr5p01S+dmNNZ0jiQ5Z1Jz9FOjN41bAsUnv9b25wue8+3GNfZKGHmO9iW4K4olW2HhnyD3Ih2aGixiEnXk1B1rYOpdsOVjmDMZ3r3Zv6U7qooDayKNTYbqQ+0fo5QWiH6dL7zVwjaBEJFwYA5wJpADXGEJgBNvKqVGK6XGAo8DTzr2rwcmOvbPAv4qIhF2zdUbZk8eSHx0BH9d6GFNoOQsXVvJnXIF+cu8L+/tDpEx+gYCnW8FkRbijuqtn+qs5RN+DoOO920sETjnKS3m797Q8e9Oc7OOfoqM1auPUCC2j3a637FG+1Y2/FPnUPzrTijzIuCjNVUlgYlgsojto6uztldc8dBOqC3tVB3kWmPnCmIysF0ptVMpVQ/MBc53PkAp5VxPIA5Qjv3VSimrGXSMtT+USIyJ5MopA1mwbh/5h6rdPzF5hM5BONzB01NZgc6otVMgQD+dgi4l3ploiWQKwZIb1Yfgg5/rOU7/tX/GjE/RUUj718HXHdz0v/+7Lqcx83eBvWm6Q3yKLvNx+2qYcJ1OsvvLOPjqMd8aFVUGqA6ThTu5EJ20gqszdgpEP8C5eXCBY99RiMitIrIDvYK43Wn/FBHZAKwDbnISDOdzbxCRFSKyoqTETwlFHnDdiYMJE+ElT8pvuNt+1CrJ7U2LUU8YMBmu+xhGXWTvdfxNfJquPmun49NbPrxb3zgufM7z/uHtMfIsXZ5j0ZNH/FOtqdgPnz6oo59al/IIJRIz4Own4PZVusrwV3+Av5/vfdvTqgDVYbJwJ5u6cKVexfmjhlqQCLqTWik1Ryk1DLgXeMBp/1KlVC4wCbhfRI75S1NKPa+UmqiUmpiSEvgQzYyePThvbF/+sTyfnSWV7p3krkDsWap/udJG+zZJdxh0fKdqgwhos0tqCDYPWv+ONp+cch9k5Pl//DP+oM2B797oOpP8o1/6Xk4jkPQaCJe8BBc8q2+oz52oM7I9oblJJ62F2gqiYAX0HaeDU2zk2+0HvC8i2gF2CkQhMMDpfX/HvraYC1zQeqdSahNQCYRkp++bThlGs1LMePJrfvq35SzcWkJzczsWsegEXSyvxI0VRL8Jtv9ydWqs7nLBrgNkUb5Prx76TdC1iuwgJlHfTA/tgk9/c/RnmxfAxvfhlF/6Xk4j0Iy9Em74GuLTdUb2Zw+53xSq+iCo5gD7ICyBaMNR3VgP+9fa7qDeW1rDza+v5P5/rrNlfDsFYjmQKSJDRCQKmA184HyAiGQ6vT0b2ObYP8RySovIIGAksNvGuXpNVloCX/9iOrdNH86aglJ+/PIyTvvz1/zt211U1LbxC57SQU2mukpta7YrvLWrkJoN9RVHMsGDiVLa79BQoyuy2insg0+C42+FFS8dedquLdfilJoLJ95h37XtJCVLNymacJ0O0X3lLB0F1hFWklxAo5j66G1bJqai9dBUb6v/oblZcfe8NTQ2Kx45L9eWa9gmEA6fwW3AJ8AmYJ5SaoOIPCoi5zkOu01ENojIauAu4BrH/pOANY797wK3KKVCNp4xvWcMd88cwbf3ncqfL88jISaSh/+1keP/8AUPvb+eHa3NT1b70baefAtXake23Q7qzk6q448iFPIhVr0K2z/TyWHJmR0f7yun/kab2N6/VT/FWuU0zrOhnEYgiewB5z6le2MXb4LnpnZc1dZKkgvkCiKml66R1paJqcVBbV8E08vf7mLxzoM8eE4Og5PtybOw1X6hlFoALGi170Gn1y4fdZRSrwGv2Tk3O4iOCOfCcf25cFx/VueX8up3u3lz2R5eXfwDUzOTueb4wUwfmUp4cpZ+8q3Yr511rbEckP0nBfYH6GykOpx/xRthxKzgzePQLp3zMHgqTL4hMNeMjNErlRdOhTcv11V/J9/QKXsOuGTUxdp+//Z1MPdKmHIznP6Ia19ZZYDrMIHOco9NansFUbhSz8em8PHN+8t5/OMtnJadxuWTBnR8gpcE3UndVRk7oBd/vnws3903g7tPz2JrUQXX/30F05/4ig/3OpKmDrRRciN/CaRkQ49egZtwZySmpy6jHMxciMoS+OcNupzCBc8GtlxJxhgapt4LBcuo7pEGM37T8TmdiT5D4aef6ryJpc/CS6e77kXesoIIcKBKXHLbFV0LV2qxtiFQoLahiTvnriaxRyR/vHg0YmMwghEIm0lJiObnMzJZdO+pPH3lONISo3lkiY73fv/zr9i8v1VryeZmyF9uf3hrVyE1OzgmpuYmWPYCPD1BF2Q758/Qy74nOVc0NDVzy+6pPNt4LleX3sQ9H+ykuv6YaPDOTUS0bs06+01dM+yvp+hIMWcqiyE8GqITAzu32CTXAlFTqn2MNjmo/+fTLWzeX8Hjl4wmKd7e6EMjEAEiMjyMc8b05e2bTuCVn59DbVgs5QUbmfXUN8x+fjHbix1+ipLNume08T+4R2qO/mN0N+LFH+Qv1w1yFtyjQ1lv/g5GXxK46wNKKe57Zx2fbTlI7Fm/46TpZ/HOqgLOf/pbthVVBHQuAWHk2bpBUWq2ruf0rzt0QAAcyaIOdFhvWyYmq3qtDQ7q73Yc4MVFu7hqykBOHWl/AyIjEEEgt18vYtJHMntwDfefOZJtRZVc/Ox3LN996EiCnBEI90jNgeYGz3pseEvVAXj/NnjpNP3UesnL8OMPdFe1APOHjzbzzqoC/uu0LK45YTB3zRzB338ymUNV9Zz39LfMX1kQ8DnZTq8BcN0CHUK88m/wwgxdGbmy+EheQiBpq2CfTS1Gy6obuHveGgYnxfHrs7P9OnZbGIEIFslZRB7ezo2nDOO9W08kKS6Kq15cSsHaL3WMdZ+hwZ5h58CqybT8JSjfa881mpv0+P83QXfhO+HncNty7UgNQjLaX7/ewfMLd/Lj4wdx+4zhLfunZqaw4I6p5A3oyT1vr+Get9d0PZNTeKRud3rVO7o74/PTtIkvkA5qi9hk3Qe7qdV3XLgSkjL97kP8zfvrKa6o46nLxxIbFZj8KCMQwSIlCyr2Ql0FA/rEMv/mExjVN5GG3Uv4IW5058iCDQVSRuq+FstfgCdzdCezVa9BrYdVdtuiYCW8OAM+vAvSR2szx8zfBb58toN5K/L5w0ebOWdMBg+fm3uMgzItMYY3rj+O22dktpictnZFk1Pmafr/ot8EfZMORs0pa9VS45Qsp5TOoPazeen91YV8sGYvd8zIJG9A4IJXjEAEi5bucro2fp+4KN68YihDwop4fW8G/71gU/sZ2QZNeCRcPR9+vgpOuVcXOfzgNvhTJsz7MWz6NzTWeT5u9SHdbOfFGTpD+uKX4Jp/OfphB4fPNhZx/z/XMTUzmScvG0tYmOuHiPAw4a7Ts3jtJ1M4XF3PeU8v4u0VIZBM6G8SM+DH78P5c/zba9tdYpP01tlRXVago6r8GG5cWFrDA++tZ9zAXtwyLbAZ8kYggoWL9qMx+7XtMjXnZJ5fuJM7/rGaukYfKlx2J5KGwfT7tVBc/wVMuFZ3c/vHVfBElnZq/vBdx13ZmpthxSvwf+N1pdHjb9XmpNGXBHVVt3TnQW57cxWj+vXkuasnEBXR8Z/uSZnJLLh9KuMG9OYX89dy97wuaHIKC9dFCVOyAn9tSyCcHdUtCXL+8T80NyvumbeGpmbFU5ePJSI8sLdsU+gnWPQeojMxnUtu5C+B8Ciuv+xCGvsV8sePN1NcXsvzP55Izx6dODs2kIjo3sv9J+iy0ju/0m1V187Tjs2eA/TNfszlx64GClfpchV7V8GgE+GsJ474OILIxr3lXP/3FfTr3YNXrp1EXLT7f7apiTG8fv0U/vKfbfzli22sKSjlmavGk5UWHBNZl8JVwb7Clbq/e5p/Sse9tEhnS//x4tEMSgp8VzqzgggWEVHaEX2UQCyDvuOQyBhunjaMpy4fy6o9h7n0ue9sq9bYpQmPhMzT4eIX4Bfb4aIXtc/i27/AM8fBsyfBt/+r8yj+/V86K7m8EC56Aa79MCTEYc/Baq55ZRlxURG89tMp9ImL8niM8DDhv07P4vWfTqG0uoHznl7EvK5ocgo0rkp+F66E9DF+qY68aV85f/pkCzNz0rhsUcUlaAAAFIVJREFUYmBzbCyMQAQTqyYT6M5Ue78/Krz1gnH9ePW6yewrreWiZ747NqnO4D5RcTDmUu2vuHsLnPm4/iP+7EF49nhY+Socd7M2J425LCSCBEoq6vjRy0tpaGrmtZ9Opl+vHj6Nd+LwZBbccRLjBvTml/PXcte81V3P5BRIrIJ9lg+iqVH/DfvBQV3b0MR//UNnS//hInuzpdvDCEQwSc7UpQOaGmHfGl39sVX+wwnDk5l3k25Zeemzi/luu/9qFpbXNvDe94Xc985a3l9dSGNTB/b5rkJ8Cky5UVcO/fkqLRY3LtQZuzE9gz07QP/fXPPyMorL63j52klk+skklJqgTU53zMjk3e8LOe/pb9myvwtGOQWC8Egao3ry9erNPPzBBvZtXwMN1X4RiCc+0dnSf7pkjO3Z0u1hfBDBJGWETvI6vFv7H8Blglx2RiL/vOUErn1lGde8sownLs3j/LHHNOdzi8NV9Xy2qYiP1+9n0bYD1Dc1ExMZxtzl+Tzx6RZ+NnUol04YQI+ocB9+sE5E0rCQ651Q29DEz15dwdaiCl68ZiLjB/b26/iWyWnykD7cMXc1589ZxKkjU0lLjCGjZwxpiTGkJ8aQ7ngdE9lNfhfcRCnFwm0HeObL7fx3bSw19UW8sfQHapd+wWORsCViBL6kTn63XWdLX33cQKaPDG7LWCMQwcQ5kmnPUu2TaKPgWN9ePXj7phO44e8ruGPuavaV1XLjyUPdWnqWVNTx6cb9fLx+P9/tOEhTs6Jfrx5cc8IgZo3KYOyAXvxnUxHPfr2DB9/fwP9+vo1rTxjMj48fTM9Y4xwPJI1Nzdz+1vcs3XWI/509lmkj7LtBWCan3/57Exv2lvH1lhKq6o+NmusVG9kiGOmJDgHpeeR9emIMvWIjg2YGCRTNzYpPNuxnzlfbWV9YTnpiDPG9Uzm9VziLLj6Vfa/Npbw4jjNeK+CEYbXceMowTs5M9uh7Katu4O631zA0OY5fnxV8H5gRiGCS5MiCPbBFl9jInNnu4T17RPL3n07m7nlreOyjzewtreGhc3MJdxEPv7+slo/X7+Oj9ftZvvsQzQqGJMdx48lDOXNUBqP6JR71izszN53Tc9JYtusQz329g//5bCvPfb2DKyYP5KdTh5DR0zf7t6FjlFI88N56Pt1YxEPn5ni9SvSE1IQY/u+KcS3vK2obKCqvZX9ZHfvKavRrx/ui8lo27C3nQGXdMa1MhibHccaodM4clc7ofj0DIhY/HKzis41FfLWlhF6xkUwfkcopI1JI9rNJpqGpmfe+L+TZr3ews6SKwUmx/PHi0Vwwrh/Rb78Eh3eTlhhDWthOGodO5ldDsnlp0S6ueXkZI9MTuPGUoZwzpi+RboSoPvD+ekoq6vjnLSeExCpeVKi0a/SRiRMnqhUrVgR7Gp7zRJYOec1fAuc8BROv6/CU5mbFHz7axAvf7OKM3DT+d/Y4YiLDyT9Uzcfr9/PR+n2s2lMKQFZaPGeOyuDM0emMSEtw+w93075y/vr1Dv61dh9hAheM7ceNpwxleKoJj7SLxz/ezDNf7eC26cO554zA13dyl4amZoor6thfVktReS2Fh2tYuK3kqNXpGbnpzBqVzoRBvV0+wHhDc7NiTUEpn20s4rONRWxzFLjMSovncHUDJRU6ITKvf0+mjUhl+shUxvTr2WZCYUfU1Dfxj+V7eH7hTvaW1ZKTkcgt04dx5qiMIz/TBz+HrZ/A7d/DH/rD1Hvg1F9T39jMB2v28tevd7CtuJK+PWP46dShzJ40oM0w5fdXF3LH3NXcfXoWP58RgKZTDkRkpVLKZWafEYhg87dzYPc3+vUtSzzK1H150S5+++FGcvsmIgjrCnV5idy+iZw5Kp1ZozIYnhrv0/TyD1Xz4jc7+ceKfGobmpmZk8ZN04b53S7e3Xnxm5387sNNXDF5IP994ahOaa4pra7n803FfLx+Hwu3HaC+sZnk+Ghm5qYxKzed44clufUU7UxtQxOLdxzk041F/GdTEcUVdYSHCZMH9+H0nDROz0ljQJ9YmpsVG/eV8+XmYr7cUsz3+aUoBUlxUZySlcK0kamcnJlMr9iOw4TLahp4fckPvLxoFwer6pk8uA83Tx/GtKyUY/9fPn8EvvuLLtr4t7Pgin8c1byquVnx1dZinvt6J8t2HSIxJoIfHT+Ia04YTGpCTMtxhaU1zHpqIZmp8cy78fiAJsQZgQhl/n2X7i0c0xN+udvjhjML1u3j1++uY1BSHGeOSufMURkMTIr1+zQPVtbx6ne7eXXxD5TVNDBlSB9umtbGH43BI+avLOCet9cwKzedOVeN99sTdzCprGvky83FfLxhP19uLqa6vonEmAhOy0njzFEZTM1MbtP5XVpdzxebi/lsYxELt2q/SFxUOKeMSOH0nDSmj0jt8EZ/qKqeb7aV8OXmYr7eWsLh6gbCBMYP7M30kalMG5FCTsbRZtaSijpe/nYXry/+gYq6RqaNSOGWacOZPKRP2xdaPAc++RWc/AtY+Ce4Z3ubfsTv9xzm+YU7+XjDfiLDw7h4fH9+NnUIg5PiuPLFJawrKGPBHVMDnhBnBCKUWfIcfHyvLjh39fxgz6ZDquoaeWvZHl5atIt9ZbVkZyRy48lDGT+wNykJ0SFhN3WmqVlxsLKO4gptQ7e2ReV1lFTo7aGqesYO7MWlE/ozNTMlIDfoyrpGPli9l7eW7WFdYRnHD03ilesmdcmIodqGJr7ZdoCP1u/j841FlNc2EhsVzvSRqczKTWf6yFQOV9Xz6cYiPtu4n+W7D9PUrEhNiOY0xyrh+KFJXn83TQ7T1Febi/lyS0nLSjstMZppWamclJnM8t2H+MfyfOqbmjlrdAY3nzKMUf3cCHleMxfevVEnx9WWwp3rOjxl14EqXvhmJ/NXFtDQ1Exu30TWF5bz+MVjuMzG9qFtYQQilNn+H3j9Ijj1Af0U0kmwbKzPfb3jSLMjID46guT4KFISovW/+GiS46Nb3luvk+Oj3aonBPoPvLahiZqGJmobmqhtaHZs9evq+kYOVtW3CECxQwCKK2opqajDVc3D5PgoUhNiSE2MJiEmkkXb9FNmemIMF43vx6UTBzDEhkbw6wrKeHPZD7y/ei/V9U2MTE/gyikDu01ocX1jM0t2HuSj9fv5bON+DlTWExEmNDr+k7LS4h2mo3Sf/AftUVxRy9dbSvhqSwkLt5ZQUddIZLhw0bj+3HjKUIameGCW3fY5vHGxfp17IVz6N7dPLamo4++Ld/P3xT9wUmYyT18xLiircSMQoUxtObzzU5j1WMjF47tDc7Ni6a5D5B+u5kBlHSUV+p/z6/Ja19m6vWIjSY6P5v/bu/cYqcozjuPf3y677Mr9IuvCAl6gjZfKNaCIxpSiSFvQihawStWEWKHRNr1otNaYtNE2vYdUrTXFliCFSqXWu7Q2tkFuAgJeuITCrlwsKLAqt+XpH+ddGIYzy8Aw56zs80kmc+Y978w8++4588x5z5z37dKmHINDH/qfZCWB/Q35b6Nd2pTTrX0FVe1b061da6raV9CtfcWh5ar2UXLK7gvfe6CB+W9tY/aSWv75zjYOGgzu3YnrB/dk9IXVtD2O8Y+y1e89wNPL6pi5cCMr63ZRWVbKl/tVM2FIL/r37Nhiu+gaDhqLN+xg/tvbOL1da0aeV5V498r+hoOsqN1Jj46VnNGh4thPyPbeG9GcFBANAz/sm8f9Eg0HDUFRkmE+PEG4VO3Z38D2j/ZFiWP3Xt6vPzKJbK/fR0kJVJSVUllWSkVZKRVlJeG+lIpWpVSWlxxarigvpaJV9LiyPCrr0rb8uI5KmrJ11x6eWlrH7CWbWP/+R1SWlTL6c9VcN7iGoWd1zusD3cx4s24nMxduPOJo4YahvRg7oAftK/z6klPCh5vgl2Fgvpufh94XpxvPCUgtQUgaBfwKKAUeM7MHs9bfBkwBGoB6YLKZrZY0EngQKAf2Ad81s/lNvZcnCHeymRlLN37InCWb+NvyzdTvPUCvzqcxblAN1w6qiR0bafee/Twdzi2seu/w0cLEob3pV5PM9QEuQfs+hh9XRyMz370pGvPrUyaVBCGpFHgXGAnUAouACWa2OqNOezPbFZbHALeb2ShJA4CtZvaepAuAF8ysyauGPEG4YvpkXwPPr9rM7MW1/GfddiQY3qcr4wbVcOX5Z/DOlt3MXLiRecujo4Vzq9szcWgvxvbv7kcLp7ofVUPnc+Abr6UdyQlpKkEU80rqIcBaM1sfgngSGAscShCNySFoA1gofyOjfBVQKam1mZ3A1GDOFa6yvJRrBtRwzYAaNu34mDlLapmzpJY7nlxGeasS9h04SGVZKWP6dWfC0F5+tNCSVF0AZw5PO4qiKGaC6AFkDjpfCxw1Ep2kKcC3ibqTPh/zOtcCS+OSg6TJwGSAXr16nYSQnTu2np1P41sjP8MdI/qyYP12nl+1hb5V7bi6f3fa+dFCy3Pri2lHUDSpj8VkZtOAaZImAvcCkxrXSTofeAiIHaTIzB4FHoWoi6n40Tp3WEmJGNanK8P6dE07FJemU/hIsZjXc9cBmVd91ISyXJ4Erm58IKkGmAvcZGbrihKhc865nIqZIBYBfSWdJakcGA/My6wgKXNEqi8Ca0J5R+DvwF1m9u8ixuiccy6HoiUIMzsATAVeAN4C/mxmqyQ9EH6xBDBV0ipJy4jOQzR2L00F+gD3SVoWbunOnOGccy2MXyjnnHMtWFM/c/U5qZ1zzsXyBOGccy6WJwjnnHOxPEE455yLdcqcpJb0PvDfAl6iK/C/kxROMXh8hfH4CuPxFaY5x9fbzGKnwTtlEkShJC3OdSa/OfD4CuPxFcbjK0xzjy8X72JyzjkXyxOEc865WJ4gDns07QCOweMrjMdXGI+vMM09vlh+DsI551wsP4JwzjkXyxOEc865WC0qQUgaJekdSWsl3RWzvrWkWWH965LOTDC2npL+IWl1GOH2jpg6l0vamTHC7X1JxZcRwwZJb4b3P2p0REV+HdpwhaSBCcX12Yx2WSZpl6Q7s+ok3n6SHpe0TdLKjLLOkl6StCbcd8rx3EmhzhpJk+LqFCm+n0p6O/z/5obh9+Oe2+S2UMT47pdUl/F/HJ3juU3u70WMb1ZGbBvCaNVxzy16+xXMzFrEDSgF1gFnE01vuhw4L6vO7cDDYXk8MCvB+KqBgWG5HfBuTHyXA8+k3I4bgK5NrB8NPAcIuAh4PaX/9RaiC4BSbT/gMmAgsDKj7CdEc50A3AU8FPO8zsD6cN8pLHdKKL4rgFZh+aG4+PLZFooY3/3Ad/LYBprc34sVX9b6nwH3pdV+hd5a0hHEEGCtma03s31EM9iNzaozFpgelucAI5TQzPNmttnMlobl3URzaPRI4r1PsrHAExZZAHSUVJ1wDCOAdWZWyJX1J4WZ/QvYkVWcuZ1NJ2MmxQxXAi+Z2Q4z+wB4CRiVRHxm9qJF87kALCCaDTIVOdovH/ns7wVrKr7w2XE9MPNkv29SWlKC6AFsynhcy9EfwIfqhB1kJ9AlkegyhK6tAcDrMasvlrRc0nNhzu6kGfCipCWSJsesz6edi208uXfKtNsPoMrMNoflLUBVTJ3m0I4AtxAdEcY51rZQTFNDF9jjObromkP7XQpsNbM1Odan2X55aUkJ4lNBUlvgL8CdZrYra/VSom6TfsBvgL8mHR8w3MwGAlcBUyRdlkIMOSma3nYMMDtmdXNovyNY1NfQLH9rLuke4AAwI0eVtLaF3wLnAP2BzUTdOM3RBJo+emjW+xK0rARRB/TMeFwTymLrSGoFdAC2JxJd9J5lRMlhhpk9lb3ezHaZWX1YfhYok9Q1qfjC+9aF+23AXKJD+Uz5tHMxXQUsNbOt2SuaQ/sFWxu73cL9tpg6qbajpK8DXwJuCEnsKHlsC0VhZlvNrMHMDgK/y/G+abdfK+ArwKxcddJqv+PRkhLEIqCvpLPCt8zxwLysOvM4PC/2OGB+rp3jZAv9lb8H3jKzn+eoc0bjORFJQ4j+f0kmsDaS2jUuE53MXJlVbR5wU/g100XAzozulCTk/NaWdvtlyNzOJgFPx9R5AbhCUqfQhXJFKCs6SaOA7wFjzOzjHHXy2RaKFV/mOa1rcrxvPvt7MX0BeNvMauNWptl+xyXts+RJ3oh+YfMu0a8b7gllDxDtCAAVRF0Ta4GFwNkJxjacqKthBbAs3EYDtwG3hTpTgVVEv8hYAAxLuP3ODu+9PMTR2IaZMQqYFtr4TWBwgvG1IfrA75BRlmr7ESWrzcB+on7wW4nOa70CrAFeBjqHuoOBxzKee0vYFtcCNycY31qi/vvG7bDxl33dgWeb2hYSiu+PYdtaQfShX50dX3h81P6eRHyh/A+N211G3cTbr9CbD7XhnHMuVkvqYnLOOXccPEE455yL5QnCOedcLE8QzjnnYnmCcM45F8sThHPNQBhp9pm043AukycI55xzsTxBOHccJH1N0sIwhv8jkkol1Uv6haJ5PF6RdHqo21/Sgox5FTqF8j6SXg6DBi6VdE54+baS5oS5GGYkNZKwc7l4gnAuT5LOBb4KXGJm/YEG4AaiK7gXm9n5wKvAD8NTngC+b2YXEl3521g+A5hm0aCBw4iuxIVoBN87gfOIrrS9pOh/lHNNaJV2AM59iowABgGLwpf7SqKB9g5yeFC2PwFPSeoAdDSzV0P5dGB2GH+nh5nNBTCzPQDh9RZaGLsnzEJ2JvBa8f8s5+J5gnAufwKmm9ndRxRKP8iqd6Lj1+zNWG7A90+XMu9ici5/rwDjJHWDQ3NL9ybaj8aFOhOB18xsJ/CBpEtD+Y3AqxbNFlgr6erwGq0lnZboX+FcnvwbinN5MrPVku4lmgWshGgEzynAR8CQsG4b0XkKiIbyfjgkgPXAzaH8RuARSQ+E17guwT/Dubz5aK7OFUhSvZm1TTsO504272JyzjkXy48gnHPOxfIjCOecc7E8QTjnnIvlCcI551wsTxDOOedieYJwzjkX6/+R3j6YxtoeXgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oixh8XG2vytt",
        "outputId": "076b01f9-ed9c-4007-affc-ef1aae01de2e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hptuning_config.yaml   prediction_input.json  requirements.txt\ttrainer\n",
            "local-training-output  README.md\t      scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "D2L4TkncQb0F"
      },
      "source": [
        "Over time, loss decreases and accuracy increases. But do they converge to a\n",
        "stable level? Are there big differences between the training and validation\n",
        "metrics (a sign of overfitting)?\n",
        "\n",
        "Learn about [how to improve your machine learning\n",
        "model](https://developers.google.com/machine-learning/crash-course/). Then, feel\n",
        "free to adjust hyperparameters or the model architecture and train again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gmTiOQObmTqd"
      },
      "source": [
        "#### Export the model for serving\n",
        "\n",
        "AI Platform requires when you [create a model version\n",
        "resource](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models#create_a_model_version).\n",
        "\n",
        "Since not all optimizers can be exported to the SavedModel format, you may see\n",
        "warnings during the export process. As long you successfully export a serving\n",
        "graph, AI Platform can used the SavedModel to serve predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNNMR0UyvPpO",
        "outputId": "c83bb864-f75c-4a3c-bfa1-1b0cc1cdb9f8"
      },
      "source": [
        "# Export the model to a local SavedModel directory \n",
        "export_path = tf.compat.v1.keras.experimental.export_saved_model(keras_model, 'keras_export')\n",
        "print(\"Model exported to: \", export_path)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-57-c5840a3be305>:2: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: keras_export/saved_model.pb\n",
            "Model exported to:  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_eIF2qfykiFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e20e5ca-6656-437c-c51c-e1ae475cbd13"
      },
      "source": [
        "# Export the model to a SavedModel directory in Cloud Storage\n",
        "export_path = tf.compat.v1.keras.experimental.export_saved_model(keras_model, JOB_DIR + '/keras_export1')\n",
        "print(\"Model exported to: \", export_path)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: gs://nooji-test-bucket/keras-job-dir/keras_export1/saved_model.pb\n",
            "Model exported to:  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "i805caqculq4"
      },
      "source": [
        "# Task 3: Deploy this model to AI Platform and serve predictions by following the steps from Part 2 (Cloud Deployment). Ensure you know all the steps to train and fetch results for test data.\n",
        "\n",
        "## Enter your code below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "x27DXeUGzb-M"
      },
      "source": [
        "## Finally, Cleaning up\n",
        "\n",
        "To clean up all GCP resources used in this project, you can [delete the GCP\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Alternatively, you can clean up individual resources by running the following\n",
        "commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "no210oWF68Uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57db389-6278-47b2-cfe0-d16cff893768"
      },
      "source": [
        "# Delete model version resource\n",
        "! gcloud ai-platform versions delete $MODEL_VERSION --quiet --model $MODEL_NAME \n",
        "\n",
        "# Delete model resource\n",
        "! gcloud ai-platform models delete $MODEL_NAME --quiet\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "! gsutil -m rm -r $JOB_DIR\n",
        "\n",
        "# If the training job is still running, cancel it\n",
        "! gcloud ai-platform jobs cancel $JOB_NAME --quiet --verbosity critical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.versions.delete) NOT_FOUND: Field: name Error: The model resource: \"fb_keras_model\" was not found. Please create the model resource first by using 'gcloud ai-platform models create fb_keras_model'.\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - description: \"The model resource: \\\"fb_keras_model\\\" was not found. Please create\\\n",
            "      \\ the model resource first by using 'gcloud ai-platform models create fb_keras_model'.\"\n",
            "    field: name\n",
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.delete) NOT_FOUND: Field: name Error: The model resource: \"fb_keras_model\" was not found. Please create the model resource first by using 'gcloud ai-platform models create fb_keras_model'.\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - description: \"The model resource: \\\"fb_keras_model\\\" was not found. Please create\\\n",
            "      \\ the model resource first by using 'gcloud ai-platform models create fb_keras_model'.\"\n",
            "    field: name\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/variables/#1611783602859892...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/variables/variables.data-00000-of-00001#1611783619060626...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/#1611783601056674...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/#1611783601455130...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/variables/checkpoint#1611783621105562...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/assets/saved_model.json#1611783629725562...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/assets/#1611783629339265...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/variables/variables.index#1611783619630260...\n",
            "Removing gs://automl-experiment-fourthbrain/keras-job-dir/keras_export/saved_model.pb#1611783628006223...\n",
            "/ [9/9 objects] 100% Done                                                       \n",
            "Operation completed over 9 objects.                                              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtRXYp034URS"
      },
      "source": [
        "gsutil rm -r gs://$BUCKET_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3F2g4OjbJ3gZ"
      },
      "source": [
        "# Ensure all your data is removed!\n",
        "Now you know how to use AutoML in GCP!\n",
        "Congratulations..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "K0UXLWaBJnrY"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "* View the [complete training\n",
        "code](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/tf-keras) used in this guide, which structures the code to accept custom\n",
        "hyperparameters as command-line flags.\n",
        "* Read about [packaging\n",
        "code](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer) for an AI Platform training job.\n",
        "* Read about [deploying a\n",
        "model](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models) to serve predictions."
      ]
    }
  ]
}